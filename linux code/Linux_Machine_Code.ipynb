{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frankross_analytic Github\n",
    "\n",
    "- [frankross_analytic_github link](https://github.com/kr2rohit/frankross_analytics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHnmuLAD9SQc",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Backup At : 4th Feb2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzL7b6TBKliy",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Orders Data update ,  Updated_at : 24th feb25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1P0rLIMAS3Q"
   },
   "outputs": [],
   "source": [
    "# Version: 1.02\n",
    "#(Removed Coupon data as they had duplicates due which duplicates orders were recorder in c42 combined and leads to double rporting)\n",
    "# Updated at 5th March25\n",
    "# updates: added promotion_id and coupon_code \n",
    "# This Script Updates current month order in Summary sheet , CC Dashboar, Re order sheet, - Logging Configured \n",
    "import schedule as schedule\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"log_Order_summary_update.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def Order_summary_update():\n",
    "    try:\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import paramiko\n",
    "        import re\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                        host='127.0.0.1',\n",
    "                        port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                        database='efrprod',\n",
    "                        user='emamireaduser',\n",
    "                        password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "        \n",
    "                logging.info('Executing DB query.....')\n",
    "                cursor.execute(\n",
    "                '''\n",
    "                SELECT order_Table.*\n",
    "                ,CASE WHEN\n",
    "                \tod IS NULL THEN 'Not First Order'\n",
    "                \tELSE '1st Order' END AS new_flag\n",
    "                ,CASE\n",
    "                 \tWHEN timeout_at IS NOT NULL THEN 'timeout'\n",
    "                \tWHEN rejected_at IS NOT NULL THEN 'rejected'\n",
    "                \tWHEN accepted_at IS NOT NULL THEN 'accepted'\n",
    "                \tELSE 'pending' end as order_action\n",
    "                --,promo.coupon_code\n",
    "                FROM\n",
    "                (SELECT\t\t\n",
    "                 osl.order_id\t\t\n",
    "                ,o.user_id as created_by_id\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN o.state =0 THEN 'cart'\t\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\t\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\t\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\t\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\t\n",
    "                \tWHEN o.state =14  THEN 'Return_completed'\t\n",
    "                \tELSE 'In-Progress'\t\n",
    "                END AS status\t\t\n",
    "                ,o.city_id\t\t\n",
    "                ,o.delivery_remarks\t\t\n",
    "                ,o.payment_method\t\t\n",
    "                ,o.auto_completed\t\t\n",
    "                ,o.order_total_paise*1.0/100 AS order_value\t\t\n",
    "                ,o.shipping_total_paise*1.0/100 AS Shipping_charge\t\t\n",
    "                ,o.doctor_names\t\t\n",
    "                --,o.delivery_slot_id, o.store_id, o.shipping_address_id, o.billing_address_id\t\t\n",
    "                ,osl.confirmed_on\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\t\n",
    "                \tWHEN osl.channel = 1 THEN 'Mobile'\t\n",
    "                \tELSE 'Website'\t\n",
    "                END as channel_name\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\t\n",
    "                \tWHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                \tWHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\t\n",
    "                \tWHEN osl.channel = 1 THEN 'Saathi App'\t\n",
    "                \tELSE 'Website'\t\n",
    "                END as channel2\t\t\n",
    "                ,CASE \t\t\n",
    "                \tWHEN o.state =0 THEN 'cart'\t\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\t\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\t\n",
    "                \tWHEN o.state =3 THEN 'order_received'\t\n",
    "                \tWHEN o.state =4 THEN 'shipped'\t\n",
    "                \tWHEN o.state =5 THEN 'out_for_delivery'\t\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\t\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\t\n",
    "                \tWHEN o.state =14 THEN 'Return_completed'\t\n",
    "                \tWHEN o.state =17 THEN 'rescheduled'\t\n",
    "                \t\tELSE 'In-Progress' END AS detailed_status\n",
    "                ,customer_id\t\t\n",
    "                ,users.name AS modified_by\t\t\n",
    "                ,w.code AS fulfillment_center\t\n",
    "                ,Wa.code AS Actual_Mapped_Dc\n",
    "                ,DS.slot_description\t\t\n",
    "                ,DS.slot_date AS Expected_Delivery\t\t\n",
    "                ,DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) AS exp_delivery_start\t\t\n",
    "                ,DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) AS exp_delivery_end\t\t\n",
    "                ,co.state_changed_on + time '5:30' as cancelled_date\t\t\n",
    "                ,co.reason\t\t\n",
    "                ,co.remarks\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN so.modified_by_id = 94098 THEN 'Ecogreen API'\t\n",
    "                \tWHEN so.modified_by_id = 25 THEN 'Vinculum API'\t\n",
    "                \tWHEN so.modified_by_id = 44306 THEN 'Delite'\t\n",
    "                \tWHEN so.modified_by_id = 162007 THEN 'Kumar Rohit'\t\n",
    "                \tWHEN so.modified_by_id = 175710 THEN 'Arun Kumar'\t\n",
    "                \tELSE 'Others'END AS shipped_by\t\n",
    "                ,so.state_changed_on + time '5:30'AS shipped\t\t\n",
    "                ,ofd.state_changed_on + time '5:30'AS out_for_delivery\t\t\n",
    "                ,del.state_changed_on + time '5:30'AS delivered_date\t\t\n",
    "                ,iv.amount_paise/100*1.0 AS invoiced_amt\t\t\n",
    "                ,iv.invoiced_at\t\t\n",
    "                ,iv.wallet_amount\t\t\n",
    "                ,ph.number\t\t\n",
    "                ,us.name AS user_name\t\t\n",
    "                ,us.created_at AS registration_date\t\t\n",
    "                ,us.registration_source\t\t\n",
    "                ,areas.pincode\n",
    "                --,op.promotion_id\n",
    "                --,op.promotion_total_paise/100*1.0 as amount_discounted\n",
    "                --,op.cash_back_total_paise/100*1.0 as cashback\n",
    "                --,promo.coupon_code\n",
    "                ,ROW_NUMBER() OVER(PARTITION BY o.user_id ORDER BY osl.confirmed_on) AS nth_order\t\t\n",
    "                --,CASE WHEN \t\t\n",
    "                --\tROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY osl.confirmed_on ASC) = 1\t\n",
    "                --\tTHEN '1st Order' ELSE 'Not First Order'\t\t\n",
    "                --END AS new_flag_month\t\n",
    "                ,CASE \t\t\n",
    "                \t WHEN del.state_changed_on + time '5:30' IS NULL THEN 'Undelivered'\t\t\n",
    "                \t WHEN del.state_changed_on + time '5:30' \t\t\n",
    "                \t < DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) THEN 'Early'\t\n",
    "                \t WHEN del.state_changed_on + time '5:30' \t\t\n",
    "                \t > DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) \t\n",
    "                \t THEN 'Delay'\t\n",
    "                \t ELSE 'Between Slot'\t\t\n",
    "                END AS delivery_flag\n",
    "                ,oah_t.created_at + time '5:30' as timeout_at\n",
    "                ,oah_a.created_at + time '5:30' as accepted_at\n",
    "                ,oah_r.created_at + time '5:30' as rejected_at\n",
    "                \n",
    "                FROM\t\t\n",
    "                \t(SELECT\t\n",
    "                \torder_id\t\n",
    "                \t,MAX(modified_by_id) modified_by_id\t\n",
    "                \t,MAX(channel) channel\t\n",
    "                \t,MAX(state_changed_on + time '5:30') AS confirmed_on\t\n",
    "                \tFROM order_status_logs\t\n",
    "                \tWHERE state_changed_on >'2025-01-31 18:30' AND to_state = 3\t\n",
    "                \tGROUP BY order_id) AS osl\t\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\t\t\n",
    "                LEFT JOIN users ON users.id = osl.modified_by_id\t\t\n",
    "                LEFT JOIN warehouses w ON w.id = o.fulfillment_center_id\n",
    "                LEFT JOIN warehouses wa ON wa.id = o.store_id\n",
    "                LEFT JOIN delivery_slots DS ON o.delivery_slot_id = DS.id\t\t\n",
    "                LEFT JOIN order_status_logs co ON co.order_id = osl.order_id AND co.to_state = 7 -- Calcelled Orders\t\t\n",
    "                LEFT JOIN order_status_logs so ON so.order_id = osl.order_id AND so.to_state = 4 -- Shipped Orders\t\t\n",
    "                LEFT JOIN order_status_logs ofd ON ofd.order_id = osl.order_id AND ofd.to_state = 5 -- out for delivery\t\t\n",
    "                LEFT JOIN order_status_logs del ON del.order_id = osl.order_id AND del.to_state = 6 -- out for delivery\t\t\n",
    "                LEFT JOIN invoices iv ON iv.order_id = osl.order_id\t\t\n",
    "                LEFT JOIN phones ph ON ph.user_id = o.user_id AND ph.deleted_at IS NULL\t\t\n",
    "                LEFT JOIN users us ON us.id = o.user_id \t\t\n",
    "                LEFT JOIN addresses ON addresses.id = o.shipping_address_id --to Get the area id \t\t\n",
    "                LEFT JOIN areas ON areas.id = addresses.area_id\n",
    "                LEFT JOIN order_assignment_histories oah_t on oah_t.order_id = osl.order_id AND oah_t.action = 'time_out'\n",
    "                LEFT JOIN order_assignment_histories oah_a on oah_a.order_id = osl.order_id AND oah_a.action = 'accept'\n",
    "                LEFT JOIN order_assignment_histories oah_r on oah_r.order_id = osl.order_id AND oah_r.action = 'reject'\n",
    "                --LEFT JOIN order_promotions op on osl.order_id = op.order_id\n",
    "                \n",
    "                ORDER BY osl.confirmed_on DESC) as order_Table\n",
    "                LEFT JOIN \n",
    "                (SELECT od FROM\n",
    "                (SELECT ord.*,\n",
    "                ROW_NUMBER() OVER (PARTITION BY ord.user_id ORDER BY ord.confirmed_on) AS order_number \n",
    "                FROM\n",
    "                (\n",
    "                SELECT \n",
    "                order_id as od\n",
    "                ,MAX(u.created_at) as registered_at\n",
    "                ,MAX(o.user_id) as user_id\n",
    "                ,MAX(state_changed_on + time '5:30') as confirmed_on\n",
    "                ,MAX(channel) as channel\n",
    "                ,MAX(modified_by_id) as modified_by\n",
    "                FROM order_status_logs osl \n",
    "                LEFT JOIN orders o on o.id = osl.order_id\n",
    "                LEFT JOIN users u on u.id = o.user_id\n",
    "                WHERE to_state = 3 and state_changed_on > '2022-12-31 18:30:00'\n",
    "                GROUP BY od\n",
    "                ) AS ord) \n",
    "                AS ordr\n",
    "                WHERE order_number = 1\n",
    "                AND COALESCE(registered_at, '1970-01-01') >= CURRENT_DATE - INTERVAL '12 MONTH'\n",
    "                --AND EXTRACT(MONTH FROM confirmed_on) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "                AND confirmed_on >= '2025-01-31 18:30:00'\n",
    "                --AND EXTRACT(YEAR FROM confirmed_on) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "                ) as first_order\n",
    "                on first_order.od = order_Table.order_id\n",
    "                --LEFT JOIN promotions promo on promo.id = order_Table.promotion_id\n",
    "                order by order_Table.confirmed_on DESC\n",
    "                ''')\n",
    "                \n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description] # Get column names from cursor description\n",
    "                df = pd.DataFrame(records, columns=columns) # Convert records to DataFrame\n",
    "                logging.info(f'{len(records)} fetched from DB anmd saved in df')\n",
    "                df = df[['order_id', 'created_by_id', 'status', 'city_id', 'delivery_remarks',\n",
    "                         'payment_method', 'new_flag', 'order_value', 'shipping_charge',\n",
    "                         'detailed_status', 'out_for_delivery', 'confirmed_on', 'channel_name',\n",
    "                         'shipped', 'fulfillment_center', 'slot_description', 'expected_delivery',\n",
    "                         'modified_by', 'reason', 'remarks', 'cancelled_date',\n",
    "                         'delivered_date', 'channel2', 'invoiced_amt', 'shipped_by',\n",
    "                         'exp_delivery_start', 'exp_delivery_end', 'delivery_flag', 'number','user_name' ,'pincode','wallet_amount'\n",
    "                         ,'order_action','actual_mapped_dc','registration_date']]\n",
    "                logging.info('Data rearranged')\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            logging.info(f'Error connecting to PostgreSQL: {error}')\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                logging.info(\"PostgreSQL connection is closed & Job Done\")\n",
    "        \n",
    "        gsheet_name = 'Summary_Epharmacy' #This google sheet will be updated\n",
    "        tab_name = 'C42_Combined' # This particular tab is to be updated\n",
    "        \n",
    "        #Updating In Summary_Epharmacy\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1etqrto99N3Tmv9Z-svwa4OtFjUewpP0KwMiflq36hrg\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f'{gsheet_name} sheet updated')\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        \n",
    "\n",
    "        #Updating In cc_daily_dashboard\n",
    "        gsheet_name = 'CC Daily Order Dashboard' #This google sheet will be updated\n",
    "        tab_name = 'C42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1_ibELjBzTBBjKeNkgsIm5EzrDo5vamHZraOjMjDqNvI\") #Key Of the google sheet - CC order dashboard\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f'{gsheet_name} sheet updated')\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        \n",
    "\n",
    "\n",
    "        #Updating In Reorder_sheet\n",
    "        gsheet_name = 'Reorder' #This google sheet will be updated\n",
    "        tab_name = 'c42_current_month' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1WBLi5ShCGQ1US-x3OxPT2mXmz8sCn5UxiqtXJ16poBU\") #Key Of the google sheet - CC order dashboard\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f'Current month tab in {gsheet_name} sheet updated')\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        \n",
    "        \n",
    "    \n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        logging.info(f\"Error connecting to PostgreSQL: {error}\")\n",
    "    finally:# Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            logging.info(\"PostgreSQL connection is closed\\n\")\n",
    "\n",
    "logging.info('Schedule the task to run every hour')\n",
    "schedule.every().hour.at(\":01\").do(Order_summary_update)\n",
    "#print(schedule.get_jobs())\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kY8cS77y_uhW"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This Script Updates current month order in Summary sheet , CC Dashboar, Re order sheet, - Logging Configured\n",
    "import schedule as schedule\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"log_Order_summary_update.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def Order_summary_update():\n",
    "    try:\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import paramiko\n",
    "        import re\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                        host='127.0.0.1',\n",
    "                        port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                        database='efrprod',\n",
    "                        user='emamireaduser',\n",
    "                        password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "\n",
    "                logging.info('Executing DB query.....')\n",
    "                cursor.execute(\n",
    "                '''\n",
    "                SELECT order_Table.*\n",
    "                ,CASE WHEN\n",
    "                \tod IS NULL THEN 'Not First Order'\n",
    "                \tELSE '1st Order' END AS new_flag\n",
    "                ,CASE\n",
    "                 \tWHEN timeout_at IS NOT NULL THEN 'timeout'\n",
    "                \tWHEN rejected_at IS NOT NULL THEN 'rejected'\n",
    "                \tWHEN accepted_at IS NOT NULL THEN 'accepted'\n",
    "                \tELSE 'pending' end as order_action\n",
    "                FROM\n",
    "                (SELECT\n",
    "                 osl.order_id\n",
    "                ,o.user_id as created_by_id\n",
    "                ,CASE\n",
    "                \tWHEN o.state =0 THEN 'cart'\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\n",
    "                \tWHEN o.state =14  THEN 'Return_completed'\n",
    "                \tELSE 'In-Progress'\n",
    "                END AS status\n",
    "                ,o.city_id\n",
    "                ,o.delivery_remarks\n",
    "                ,o.payment_method\n",
    "                ,o.auto_completed\n",
    "                ,o.order_total_paise*1.0/100 AS order_value\n",
    "                ,o.shipping_total_paise*1.0/100 AS Shipping_charge\n",
    "                ,o.doctor_names\n",
    "                --,o.delivery_slot_id, o.store_id, o.shipping_address_id, o.billing_address_id\n",
    "                ,osl.confirmed_on\n",
    "                ,CASE\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\n",
    "                \tWHEN osl.channel = 1 THEN 'Mobile'\n",
    "                \tELSE 'Website'\n",
    "                END as channel_name\n",
    "                ,CASE\n",
    "                \tWHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                \tWHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                \tWHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\n",
    "                \tWHEN osl.channel = 1 THEN 'Saathi App'\n",
    "                \tELSE 'Website'\n",
    "                END as channel2\n",
    "                ,CASE\n",
    "                \tWHEN o.state =0 THEN 'cart'\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\n",
    "                \tWHEN o.state =3 THEN 'order_received'\n",
    "                \tWHEN o.state =4 THEN 'shipped'\n",
    "                \tWHEN o.state =5 THEN 'out_for_delivery'\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\n",
    "                \tWHEN o.state =14 THEN 'Return_completed'\n",
    "                \tWHEN o.state =17 THEN 'rescheduled'\n",
    "                \t\tELSE 'In-Progress' END AS detailed_status\n",
    "                ,customer_id\n",
    "                ,users.name AS modified_by\n",
    "                ,w.code AS fulfillment_center\n",
    "                ,Wa.code AS Actual_Mapped_Dc\n",
    "                ,DS.slot_description\n",
    "                ,DS.slot_date AS Expected_Delivery\n",
    "                ,DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) AS exp_delivery_start\n",
    "                ,DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) AS exp_delivery_end\n",
    "                ,co.state_changed_on + time '5:30' as cancelled_date\n",
    "                ,co.reason\n",
    "                ,co.remarks\n",
    "                ,CASE\n",
    "                \tWHEN so.modified_by_id = 94098 THEN 'Ecogreen API'\n",
    "                \tWHEN so.modified_by_id = 25 THEN 'Vinculum API'\n",
    "                \tWHEN so.modified_by_id = 44306 THEN 'Delite'\n",
    "                \tWHEN so.modified_by_id = 162007 THEN 'Kumar Rohit'\n",
    "                \tWHEN so.modified_by_id = 175710 THEN 'Arun Kumar'\n",
    "                \tELSE 'Others'END AS shipped_by\n",
    "                ,so.state_changed_on + time '5:30'AS shipped\n",
    "                ,ofd.state_changed_on + time '5:30'AS out_for_delivery\n",
    "                ,del.state_changed_on + time '5:30'AS delivered_date\n",
    "                ,iv.amount_paise/100*1.0 AS invoiced_amt\n",
    "                ,iv.invoiced_at\n",
    "                ,iv.wallet_amount\n",
    "                ,ph.number\n",
    "                ,us.name AS user_name\n",
    "                ,us.created_at AS registration_date\n",
    "                ,us.registration_source\n",
    "                ,areas.pincode\n",
    "                ,ROW_NUMBER() OVER(PARTITION BY o.user_id ORDER BY osl.confirmed_on) AS nth_order\n",
    "                --,CASE WHEN\n",
    "                --\tROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY osl.confirmed_on ASC) = 1\n",
    "                --\tTHEN '1st Order' ELSE 'Not First Order'\n",
    "                --END AS new_flag_month\n",
    "                ,CASE\n",
    "                \t WHEN del.state_changed_on + time '5:30' IS NULL THEN 'Undelivered'\n",
    "                \t WHEN del.state_changed_on + time '5:30'\n",
    "                \t < DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) THEN 'Early'\n",
    "                \t WHEN del.state_changed_on + time '5:30'\n",
    "                \t > DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME)\n",
    "                \t THEN 'Delay'\n",
    "                \t ELSE 'Between Slot'\n",
    "                END AS delivery_flag\n",
    "                ,oah_t.created_at + time '5:30' as timeout_at\n",
    "                ,oah_a.created_at + time '5:30' as accepted_at\n",
    "                ,oah_r.created_at + time '5:30' as rejected_at\n",
    "\n",
    "                FROM\n",
    "                \t(SELECT\n",
    "                \torder_id\n",
    "                \t,MAX(modified_by_id) modified_by_id\n",
    "                \t,MAX(channel) channel\n",
    "                \t,MAX(state_changed_on + time '5:30') AS confirmed_on\n",
    "                \tFROM order_status_logs\n",
    "                \tWHERE state_changed_on >'2024-12-31 18:30' AND to_state = 3\n",
    "                \tGROUP BY order_id) AS osl\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\n",
    "                LEFT JOIN users ON users.id = osl.modified_by_id\n",
    "                LEFT JOIN warehouses w ON w.id = o.fulfillment_center_id\n",
    "                LEFT JOIN warehouses wa ON wa.id = o.store_id\n",
    "                LEFT JOIN delivery_slots DS ON o.delivery_slot_id = DS.id\n",
    "                LEFT JOIN order_status_logs co ON co.order_id = osl.order_id AND co.to_state = 7 -- Calcelled Orders\n",
    "                LEFT JOIN order_status_logs so ON so.order_id = osl.order_id AND so.to_state = 4 -- Shipped Orders\n",
    "                LEFT JOIN order_status_logs ofd ON ofd.order_id = osl.order_id AND ofd.to_state = 5 -- out for delivery\n",
    "                LEFT JOIN order_status_logs del ON del.order_id = osl.order_id AND del.to_state = 6 -- out for delivery\n",
    "                LEFT JOIN invoices iv ON iv.order_id = osl.order_id\n",
    "                LEFT JOIN phones ph ON ph.user_id = o.user_id AND ph.deleted_at IS NULL\n",
    "                LEFT JOIN users us ON us.id = o.user_id\n",
    "                LEFT JOIN addresses ON addresses.id = o.shipping_address_id --to Get the area id\n",
    "                LEFT JOIN areas ON areas.id = addresses.area_id\n",
    "                LEFT JOIN order_assignment_histories oah_t on oah_t.order_id = osl.order_id AND oah_t.action = 'time_out'\n",
    "                LEFT JOIN order_assignment_histories oah_a on oah_a.order_id = osl.order_id AND oah_a.action = 'accept'\n",
    "                LEFT JOIN order_assignment_histories oah_r on oah_r.order_id = osl.order_id AND oah_r.action = 'reject'\n",
    "                ORDER BY osl.confirmed_on DESC) as order_Table\n",
    "                LEFT JOIN\n",
    "                (SELECT od FROM\n",
    "                (SELECT ord.*,\n",
    "                ROW_NUMBER() OVER (PARTITION BY ord.user_id ORDER BY ord.confirmed_on) AS order_number\n",
    "                FROM\n",
    "                (\n",
    "                SELECT\n",
    "                order_id as od\n",
    "                ,MAX(u.created_at) as registered_at\n",
    "                ,MAX(o.user_id) as user_id\n",
    "                ,MAX(state_changed_on + time '5:30') as confirmed_on\n",
    "                ,MAX(channel) as channel\n",
    "                ,MAX(modified_by_id) as modified_by\n",
    "                FROM order_status_logs osl\n",
    "                LEFT JOIN orders o on o.id = osl.order_id\n",
    "                LEFT JOIN users u on u.id = o.user_id\n",
    "                WHERE to_state = 3 and state_changed_on > '2022-12-31 18:30:00'\n",
    "                GROUP BY od\n",
    "                ) AS ord)\n",
    "                AS ordr\n",
    "                WHERE order_number = 1\n",
    "                AND COALESCE(registered_at, '1970-01-01') >= CURRENT_DATE - INTERVAL '12 MONTH'\n",
    "                --AND EXTRACT(MONTH FROM confirmed_on) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "                AND confirmed_on >= '2024-12-31 18:30:00'\n",
    "                --AND EXTRACT(YEAR FROM confirmed_on) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "                ) as first_order\n",
    "                on first_order.od = order_Table.order_id\n",
    "                order by order_Table.confirmed_on DESC\n",
    "                ''')\n",
    "\n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description] # Get column names from cursor description\n",
    "                df = pd.DataFrame(records, columns=columns) # Convert records to DataFrame\n",
    "                logging.info(f'{len(records)} fetched from DB anmd saved in df')\n",
    "                df = df[['order_id', 'created_by_id', 'status', 'city_id', 'delivery_remarks',\n",
    "                         'payment_method', 'new_flag', 'order_value', 'shipping_charge',\n",
    "                         'detailed_status', 'out_for_delivery', 'confirmed_on', 'channel_name',\n",
    "                         'shipped', 'fulfillment_center', 'slot_description', 'expected_delivery',\n",
    "                         'modified_by', 'reason', 'remarks', 'cancelled_date',\n",
    "                         'delivered_date', 'channel2', 'invoiced_amt', 'shipped_by',\n",
    "                         'exp_delivery_start', 'exp_delivery_end', 'delivery_flag', 'number','user_name' ,'pincode','wallet_amount'\n",
    "                         ,'order_action','actual_mapped_dc']]\n",
    "                logging.info('Data rearranged')\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            logging.info(f'Error connecting to PostgreSQL: {error}')\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                logging.info(\"PostgreSQL connection is closed & Job Done\")\n",
    "\n",
    "        gsheet_name = 'Summary_Epharmacy' #This google sheet will be updated\n",
    "        tab_name = 'C42_Combined' # This particular tab is to be updated\n",
    "\n",
    "        #Updating In Summary_Epharmacy\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1etqrto99N3Tmv9Z-svwa4OtFjUewpP0KwMiflq36hrg\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f'{gsheet_name} sheet updated')\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "\n",
    "\n",
    "        #Updating In cc_daily_dashboard\n",
    "        gsheet_name = 'CC Daily Order Dashboard' #This google sheet will be updated\n",
    "        tab_name = 'C42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1_ibELjBzTBBjKeNkgsIm5EzrDo5vamHZraOjMjDqNvI\") #Key Of the google sheet - CC order dashboard\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f'{gsheet_name} sheet updated')\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "\n",
    "\n",
    "\n",
    "        #Updating In Reorder_sheet\n",
    "        gsheet_name = 'Reorder' #This google sheet will be updated\n",
    "        tab_name = 'c42_current_month' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1WBLi5ShCGQ1US-x3OxPT2mXmz8sCn5UxiqtXJ16poBU\") #Key Of the google sheet - CC order dashboard\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f'{gsheet_name} sheet updated')\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "\n",
    "\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        logging.info(f\"Error connecting to PostgreSQL: {error}\")\n",
    "    finally:# Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            logging.info(\"PostgreSQL connection is closed\\n\")\n",
    "\n",
    "logging.info('Schedule the task to run every hour')\n",
    "schedule.every().hour.at(\":01\").do(Order_summary_update)\n",
    "#print(schedule.get_jobs())\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "It04fqOWFmW6"
   },
   "outputs": [],
   "source": [
    "# This Script Updates current month order in Summary sheet , CC Dashboar, Re order sheet, - Logging Configured\n",
    "import schedule as schedule\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"log_Order_summary_update.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def Order_summary_update():\n",
    "    try:\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import paramiko\n",
    "        import re\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                        host='127.0.0.1',\n",
    "                        port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                        database='efrprod',\n",
    "                        user='emamireaduser',\n",
    "                        password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "\n",
    "                logging.info('Executing DB query.....')\n",
    "                cursor.execute(\n",
    "                '''\n",
    "                SELECT order_Table.*\n",
    "                ,CASE WHEN\n",
    "                \tod IS NULL THEN 'Not First Order'\n",
    "                \tELSE '1st Order' END AS new_flag\n",
    "                ,CASE\n",
    "                 \tWHEN timeout_at IS NOT NULL THEN 'timeout'\n",
    "                \tWHEN rejected_at IS NOT NULL THEN 'rejected'\n",
    "                \tWHEN accepted_at IS NOT NULL THEN 'accepted'\n",
    "                \tELSE 'pending' end as order_action\n",
    "                FROM\n",
    "                (SELECT\n",
    "                 osl.order_id\n",
    "                ,o.user_id as created_by_id\n",
    "                ,CASE\n",
    "                \tWHEN o.state =0 THEN 'cart'\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\n",
    "                \tWHEN o.state =14  THEN 'Return_completed'\n",
    "                \tELSE 'In-Progress'\n",
    "                END AS status\n",
    "                ,o.city_id\n",
    "                ,o.delivery_remarks\n",
    "                ,o.payment_method\n",
    "                ,o.auto_completed\n",
    "                ,o.order_total_paise*1.0/100 AS order_value\n",
    "                ,o.shipping_total_paise*1.0/100 AS Shipping_charge\n",
    "                ,o.doctor_names\n",
    "                --,o.delivery_slot_id, o.store_id, o.shipping_address_id, o.billing_address_id\n",
    "                ,osl.confirmed_on\n",
    "                ,CASE\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\n",
    "                \tWHEN osl.channel = 1 THEN 'Mobile'\n",
    "                \tELSE 'Website'\n",
    "                END as channel_name\n",
    "                ,CASE\n",
    "                \tWHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                \tWHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                \tWHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\n",
    "                \tWHEN osl.channel = 1 THEN 'Saathi App'\n",
    "                \tELSE 'Website'\n",
    "                END as channel2\n",
    "                ,CASE\n",
    "                \tWHEN o.state =0 THEN 'cart'\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\n",
    "                \tWHEN o.state =3 THEN 'order_received'\n",
    "                \tWHEN o.state =4 THEN 'shipped'\n",
    "                \tWHEN o.state =5 THEN 'out_for_delivery'\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\n",
    "                \tWHEN o.state =14 THEN 'Return_completed'\n",
    "                \tWHEN o.state =17 THEN 'rescheduled'\n",
    "                \t\tELSE 'In-Progress' END AS detailed_status\n",
    "                ,customer_id\n",
    "                ,users.name AS modified_by\n",
    "                ,w.code AS fulfillment_center\n",
    "                ,Wa.code AS Actual_Mapped_Dc\n",
    "                ,DS.slot_description\n",
    "                ,DS.slot_date AS Expected_Delivery\n",
    "                ,DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) AS exp_delivery_start\n",
    "                ,DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) AS exp_delivery_end\n",
    "                ,co.state_changed_on + time '5:30' as cancelled_date\n",
    "                ,co.reason\n",
    "                ,co.remarks\n",
    "                ,CASE\n",
    "                \tWHEN so.modified_by_id = 94098 THEN 'Ecogreen API'\n",
    "                \tWHEN so.modified_by_id = 25 THEN 'Vinculum API'\n",
    "                \tWHEN so.modified_by_id = 44306 THEN 'Delite'\n",
    "                \tWHEN so.modified_by_id = 162007 THEN 'Kumar Rohit'\n",
    "                \tWHEN so.modified_by_id = 175710 THEN 'Arun Kumar'\n",
    "                \tELSE 'Others'END AS shipped_by\n",
    "                ,so.state_changed_on + time '5:30'AS shipped\n",
    "                ,ofd.state_changed_on + time '5:30'AS out_for_delivery\n",
    "                ,del.state_changed_on + time '5:30'AS delivered_date\n",
    "                ,iv.amount_paise/100*1.0 AS invoiced_amt\n",
    "                ,iv.invoiced_at\n",
    "                ,iv.wallet_amount\n",
    "                ,ph.number\n",
    "                ,us.name AS user_name\n",
    "                ,us.created_at AS registration_date\n",
    "                ,us.registration_source\n",
    "                ,areas.pincode\n",
    "                ,ROW_NUMBER() OVER(PARTITION BY o.user_id ORDER BY osl.confirmed_on) AS nth_order\n",
    "                --,CASE WHEN\n",
    "                --\tROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY osl.confirmed_on ASC) = 1\n",
    "                --\tTHEN '1st Order' ELSE 'Not First Order'\n",
    "                --END AS new_flag_month\n",
    "                ,CASE\n",
    "                \t WHEN del.state_changed_on + time '5:30' IS NULL THEN 'Undelivered'\n",
    "                \t WHEN del.state_changed_on + time '5:30'\n",
    "                \t < DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) THEN 'Early'\n",
    "                \t WHEN del.state_changed_on + time '5:30'\n",
    "                \t > DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME)\n",
    "                \t THEN 'Delay'\n",
    "                \t ELSE 'Between Slot'\n",
    "                END AS delivery_flag\n",
    "                ,oah_t.created_at + time '5:30' as timeout_at\n",
    "                ,oah_a.created_at + time '5:30' as accepted_at\n",
    "                ,oah_r.created_at + time '5:30' as rejected_at\n",
    "\n",
    "                FROM\n",
    "                \t(SELECT\n",
    "                \torder_id\n",
    "                \t,MAX(modified_by_id) modified_by_id\n",
    "                \t,MAX(channel) channel\n",
    "                \t,MAX(state_changed_on + time '5:30') AS confirmed_on\n",
    "                \tFROM order_status_logs\n",
    "                \tWHERE state_changed_on >'2024-12-31 18:30' AND to_state = 3\n",
    "                \tGROUP BY order_id) AS osl\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\n",
    "                LEFT JOIN users ON users.id = osl.modified_by_id\n",
    "                LEFT JOIN warehouses w ON w.id = o.fulfillment_center_id\n",
    "                LEFT JOIN warehouses wa ON wa.id = o.store_id\n",
    "                LEFT JOIN delivery_slots DS ON o.delivery_slot_id = DS.id\n",
    "                LEFT JOIN order_status_logs co ON co.order_id = osl.order_id AND co.to_state = 7 -- Calcelled Orders\n",
    "                LEFT JOIN order_status_logs so ON so.order_id = osl.order_id AND so.to_state = 4 -- Shipped Orders\n",
    "                LEFT JOIN order_status_logs ofd ON ofd.order_id = osl.order_id AND ofd.to_state = 5 -- out for delivery\n",
    "                LEFT JOIN order_status_logs del ON del.order_id = osl.order_id AND del.to_state = 6 -- out for delivery\n",
    "                LEFT JOIN invoices iv ON iv.order_id = osl.order_id\n",
    "                LEFT JOIN phones ph ON ph.user_id = o.user_id AND ph.deleted_at IS NULL\n",
    "                LEFT JOIN users us ON us.id = o.user_id\n",
    "                LEFT JOIN addresses ON addresses.id = o.shipping_address_id --to Get the area id\n",
    "                LEFT JOIN areas ON areas.id = addresses.area_id\n",
    "                LEFT JOIN order_assignment_histories oah_t on oah_t.order_id = osl.order_id AND oah_t.action = 'time_out'\n",
    "                LEFT JOIN order_assignment_histories oah_a on oah_a.order_id = osl.order_id AND oah_a.action = 'accept'\n",
    "                LEFT JOIN order_assignment_histories oah_r on oah_r.order_id = osl.order_id AND oah_r.action = 'reject'\n",
    "                ORDER BY osl.confirmed_on DESC) as order_Table\n",
    "                LEFT JOIN\n",
    "                (SELECT od FROM\n",
    "                (SELECT ord.*,\n",
    "                ROW_NUMBER() OVER (PARTITION BY ord.user_id ORDER BY ord.confirmed_on) AS order_number\n",
    "                FROM\n",
    "                (\n",
    "                SELECT\n",
    "                order_id as od\n",
    "                ,MAX(u.created_at) as registered_at\n",
    "                ,MAX(o.user_id) as user_id\n",
    "                ,MAX(state_changed_on + time '5:30') as confirmed_on\n",
    "                ,MAX(channel) as channel\n",
    "                ,MAX(modified_by_id) as modified_by\n",
    "                FROM order_status_logs osl\n",
    "                LEFT JOIN orders o on o.id = osl.order_id\n",
    "                LEFT JOIN users u on u.id = o.user_id\n",
    "                WHERE to_state = 3 and state_changed_on > '2022-12-31 18:30:00'\n",
    "                GROUP BY od\n",
    "                ) AS ord)\n",
    "                AS ordr\n",
    "                WHERE order_number = 1\n",
    "                AND COALESCE(registered_at, '1970-01-01') >= CURRENT_DATE - INTERVAL '12 MONTH'\n",
    "                --AND EXTRACT(MONTH FROM confirmed_on) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "                AND confirmed_on >= '2024-12-31 18:30:00'\n",
    "                --AND EXTRACT(YEAR FROM confirmed_on) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "                ) as first_order\n",
    "                on first_order.od = order_Table.order_id\n",
    "                order by order_Table.confirmed_on DESC\n",
    "                ''')\n",
    "\n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description] # Get column names from cursor description\n",
    "                df = pd.DataFrame(records, columns=columns) # Convert records to DataFrame\n",
    "                logging.info(f'{len(records)} fetched from DB anmd saved in df')\n",
    "                df = df[['order_id', 'created_by_id', 'status', 'city_id', 'delivery_remarks',\n",
    "                         'payment_method', 'new_flag', 'order_value', 'shipping_charge',\n",
    "                         'detailed_status', 'out_for_delivery', 'confirmed_on', 'channel_name',\n",
    "                         'shipped', 'fulfillment_center', 'slot_description', 'expected_delivery',\n",
    "                         'modified_by', 'reason', 'remarks', 'cancelled_date',\n",
    "                         'delivered_date', 'channel2', 'invoiced_amt', 'shipped_by',\n",
    "                         'exp_delivery_start', 'exp_delivery_end', 'delivery_flag', 'number','user_name' ,'pincode','wallet_amount'\n",
    "                         ,'order_action','actual_mapped_dc']]\n",
    "                logging.info('Data rearranged')\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            logging.info(f'Error connecting to PostgreSQL: {error}')\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                logging.info(\"PostgreSQL connection is closed & Job Done\")\n",
    "\n",
    "        gsheet_name = 'Summary_Epharmacy' #This google sheet will be updated\n",
    "        tab_name = 'C42_Combined' # This particular tab is to be updated\n",
    "\n",
    "        #Updating In Summary_Epharmacy\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1etqrto99N3Tmv9Z-svwa4OtFjUewpP0KwMiflq36hrg\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f'{gsheet_name} sheet updated')\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "\n",
    "\n",
    "        #Updating In cc_daily_dashboard\n",
    "        gsheet_name = 'CC Daily Order Dashboard' #This google sheet will be updated\n",
    "        tab_name = 'C42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1_ibELjBzTBBjKeNkgsIm5EzrDo5vamHZraOjMjDqNvI\") #Key Of the google sheet - CC order dashboard\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f'{gsheet_name} sheet updated')\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "\n",
    "\n",
    "\n",
    "        #Updating In Reorder_sheet\n",
    "        gsheet_name = 'Reorder' #This google sheet will be updated\n",
    "        tab_name = 'c42_current_month' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1WBLi5ShCGQ1US-x3OxPT2mXmz8sCn5UxiqtXJ16poBU\") #Key Of the google sheet - CC order dashboard\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f'{gsheet_name} sheet updated')\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "\n",
    "\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        logging.info(f\"Error connecting to PostgreSQL: {error}\")\n",
    "    finally:# Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            logging.info(\"PostgreSQL connection is closed\\n\")\n",
    "\n",
    "logging.info('Schedule the task to run every hour')\n",
    "schedule.every().hour.at(\":57\").do(Order_summary_update)\n",
    "#print(schedule.get_jobs())\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ljh8IevK0_X2",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#This script updates orders data - updates : added order_action and actual mapped dc and Fulfillment center\n",
    "\n",
    "import schedule as schedule\n",
    "import time\n",
    "def Order_summary_update():\n",
    "    try:\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import paramiko\n",
    "        import re\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                        host='127.0.0.1',\n",
    "                        port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                        database='efrprod',\n",
    "                        user='emamireaduser',\n",
    "                        password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "\n",
    "                # Perform database operations here\n",
    "                cursor.execute(\n",
    "                '''\n",
    "                SELECT order_Table.*\n",
    "                ,CASE WHEN\n",
    "                \tod IS NULL THEN 'Not First Order'\n",
    "                \tELSE '1st Order' END AS new_flag\n",
    "                ,CASE\n",
    "                 \tWHEN timeout_at IS NOT NULL THEN 'timeout'\n",
    "                \tWHEN rejected_at IS NOT NULL THEN 'rejected'\n",
    "                \tWHEN accepted_at IS NOT NULL THEN 'accepted'\n",
    "                \tELSE 'pending' end as order_action\n",
    "                FROM\n",
    "                (SELECT\n",
    "                 osl.order_id\n",
    "                ,o.user_id as created_by_id\n",
    "                ,CASE\n",
    "                \tWHEN o.state =0 THEN 'cart'\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\n",
    "                \tWHEN o.state =14  THEN 'Return_completed'\n",
    "                \tELSE 'In-Progress'\n",
    "                END AS status\n",
    "                ,o.city_id\n",
    "                ,o.delivery_remarks\n",
    "                ,o.payment_method\n",
    "                ,o.auto_completed\n",
    "                ,o.order_total_paise*1.0/100 AS order_value\n",
    "                ,o.shipping_total_paise*1.0/100 AS Shipping_charge\n",
    "                ,o.doctor_names\n",
    "                --,o.delivery_slot_id, o.store_id, o.shipping_address_id, o.billing_address_id\n",
    "                ,osl.confirmed_on\n",
    "                ,CASE\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\n",
    "                \tWHEN osl.channel = 1 THEN 'Mobile'\n",
    "                \tELSE 'Website'\n",
    "                END as channel_name\n",
    "                ,CASE\n",
    "                \tWHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                \tWHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                \tWHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\n",
    "                \tWHEN osl.channel = 1 THEN 'Saathi App'\n",
    "                \tELSE 'Website'\n",
    "                END as channel2\n",
    "                ,CASE\n",
    "                \tWHEN o.state =0 THEN 'cart'\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\n",
    "                \tWHEN o.state =3 THEN 'order_received'\n",
    "                \tWHEN o.state =4 THEN 'shipped'\n",
    "                \tWHEN o.state =5 THEN 'out_for_delivery'\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\n",
    "                \tWHEN o.state =14 THEN 'Return_completed'\n",
    "                \tWHEN o.state =17 THEN 'rescheduled'\n",
    "                \t\tELSE 'In-Progress' END AS detailed_status\n",
    "                ,customer_id\n",
    "                ,users.name AS modified_by\n",
    "                ,w.code AS fulfillment_center\n",
    "                ,Wa.code AS Actual_Mapped_Dc\n",
    "                ,DS.slot_description\n",
    "                ,DS.slot_date AS Expected_Delivery\n",
    "                ,DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) AS exp_delivery_start\n",
    "                ,DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) AS exp_delivery_end\n",
    "                ,co.state_changed_on + time '5:30' as cancelled_date\n",
    "                ,co.reason\n",
    "                ,co.remarks\n",
    "                ,CASE\n",
    "                \tWHEN so.modified_by_id = 94098 THEN 'Ecogreen API'\n",
    "                \tWHEN so.modified_by_id = 25 THEN 'Vinculum API'\n",
    "                \tWHEN so.modified_by_id = 44306 THEN 'Delite'\n",
    "                \tWHEN so.modified_by_id = 162007 THEN 'Kumar Rohit'\n",
    "                \tWHEN so.modified_by_id = 175710 THEN 'Arun Kumar'\n",
    "                \tELSE 'Others'END AS shipped_by\n",
    "                ,so.state_changed_on + time '5:30'AS shipped\n",
    "                ,ofd.state_changed_on + time '5:30'AS out_for_delivery\n",
    "                ,del.state_changed_on + time '5:30'AS delivered_date\n",
    "                ,iv.amount_paise/100*1.0 AS invoiced_amt\n",
    "                ,iv.invoiced_at\n",
    "                ,iv.wallet_amount\n",
    "                ,ph.number\n",
    "                ,us.name AS user_name\n",
    "                ,us.created_at AS registration_date\n",
    "                ,us.registration_source\n",
    "                ,areas.pincode\n",
    "                ,ROW_NUMBER() OVER(PARTITION BY o.user_id ORDER BY osl.confirmed_on) AS nth_order\n",
    "                --,CASE WHEN\n",
    "                --\tROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY osl.confirmed_on ASC) = 1\n",
    "                --\tTHEN '1st Order' ELSE 'Not First Order'\n",
    "                --END AS new_flag_month\n",
    "                ,CASE\n",
    "                \t WHEN del.state_changed_on + time '5:30' IS NULL THEN 'Undelivered'\n",
    "                \t WHEN del.state_changed_on + time '5:30'\n",
    "                \t < DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) THEN 'Early'\n",
    "                \t WHEN del.state_changed_on + time '5:30'\n",
    "                \t > DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME)\n",
    "                \t THEN 'Delay'\n",
    "                \t ELSE 'Between Slot'\n",
    "                END AS delivery_flag\n",
    "                ,oah_t.created_at + time '5:30' as timeout_at\n",
    "                ,oah_a.created_at + time '5:30' as accepted_at\n",
    "                ,oah_r.created_at + time '5:30' as rejected_at\n",
    "\n",
    "                FROM\n",
    "                \t(SELECT\n",
    "                \torder_id\n",
    "                \t,MAX(modified_by_id) modified_by_id\n",
    "                \t,MAX(channel) channel\n",
    "                \t,MAX(state_changed_on + time '5:30') AS confirmed_on\n",
    "                \tFROM order_status_logs\n",
    "                \tWHERE state_changed_on >'2024-12-31 18:30' AND to_state = 3\n",
    "                \tGROUP BY order_id) AS osl\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\n",
    "                LEFT JOIN users ON users.id = osl.modified_by_id\n",
    "                LEFT JOIN warehouses w ON w.id = o.fulfillment_center_id\n",
    "                LEFT JOIN warehouses wa ON wa.id = o.store_id\n",
    "                LEFT JOIN delivery_slots DS ON o.delivery_slot_id = DS.id\n",
    "                LEFT JOIN order_status_logs co ON co.order_id = osl.order_id AND co.to_state = 7 -- Calcelled Orders\n",
    "                LEFT JOIN order_status_logs so ON so.order_id = osl.order_id AND so.to_state = 4 -- Shipped Orders\n",
    "                LEFT JOIN order_status_logs ofd ON ofd.order_id = osl.order_id AND ofd.to_state = 5 -- out for delivery\n",
    "                LEFT JOIN order_status_logs del ON del.order_id = osl.order_id AND del.to_state = 6 -- out for delivery\n",
    "                LEFT JOIN invoices iv ON iv.order_id = osl.order_id\n",
    "                LEFT JOIN phones ph ON ph.user_id = o.user_id AND ph.deleted_at IS NULL\n",
    "                LEFT JOIN users us ON us.id = o.user_id\n",
    "                LEFT JOIN addresses ON addresses.id = o.shipping_address_id --to Get the area id\n",
    "                LEFT JOIN areas ON areas.id = addresses.area_id\n",
    "                LEFT JOIN order_assignment_histories oah_t on oah_t.order_id = osl.order_id AND oah_t.action = 'time_out'\n",
    "                LEFT JOIN order_assignment_histories oah_a on oah_a.order_id = osl.order_id AND oah_a.action = 'accept'\n",
    "                LEFT JOIN order_assignment_histories oah_r on oah_r.order_id = osl.order_id AND oah_r.action = 'reject'\n",
    "                ORDER BY osl.confirmed_on DESC) as order_Table\n",
    "                LEFT JOIN\n",
    "                (SELECT od FROM\n",
    "                (SELECT ord.*,\n",
    "                ROW_NUMBER() OVER (PARTITION BY ord.user_id ORDER BY ord.confirmed_on) AS order_number\n",
    "                FROM\n",
    "                (\n",
    "                SELECT\n",
    "                order_id as od\n",
    "                ,MAX(u.created_at) as registered_at\n",
    "                ,MAX(o.user_id) as user_id\n",
    "                ,MAX(state_changed_on + time '5:30') as confirmed_on\n",
    "                ,MAX(channel) as channel\n",
    "                ,MAX(modified_by_id) as modified_by\n",
    "                FROM order_status_logs osl\n",
    "                LEFT JOIN orders o on o.id = osl.order_id\n",
    "                LEFT JOIN users u on u.id = o.user_id\n",
    "                WHERE to_state = 3 and state_changed_on > '2022-12-31 18:30:00'\n",
    "                GROUP BY od\n",
    "                ) AS ord)\n",
    "                AS ordr\n",
    "                WHERE order_number = 1\n",
    "                AND COALESCE(registered_at, '1970-01-01') >= CURRENT_DATE - INTERVAL '12 MONTH'\n",
    "                --AND EXTRACT(MONTH FROM confirmed_on) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "                AND confirmed_on >= '2024-12-31 18:30:00'\n",
    "                --AND EXTRACT(YEAR FROM confirmed_on) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "                ) as first_order\n",
    "                on first_order.od = order_Table.order_id\n",
    "                order by order_Table.confirmed_on DESC\n",
    "                ''')\n",
    "\n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description] # Get column names from cursor description\n",
    "                df = pd.DataFrame(records, columns=columns) # Convert records to DataFrame\n",
    "                df = df[['order_id', 'created_by_id', 'status', 'city_id', 'delivery_remarks',\n",
    "                         'payment_method', 'new_flag', 'order_value', 'shipping_charge',\n",
    "                         'detailed_status', 'out_for_delivery', 'confirmed_on', 'channel_name',\n",
    "                         'shipped', 'fulfillment_center', 'slot_description', 'expected_delivery',\n",
    "                         'modified_by', 'reason', 'remarks', 'cancelled_date',\n",
    "                         'delivered_date', 'channel2', 'invoiced_amt', 'shipped_by',\n",
    "                         'exp_delivery_start', 'exp_delivery_end', 'delivery_flag', 'number','user_name' ,'pincode','wallet_amount'\n",
    "                         ,'order_action','actual_mapped_dc']]\n",
    "                print(\"Data fetched and saved to df\")\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            print(\"Error connecting to PostgreSQL:\", error)\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "        gsheet_name = 'Summary_Epharmacy' #This google sheet will be updated\n",
    "        tab_name = 'C42_Combined' # This particular tab is to be updated\n",
    "\n",
    "        #Updating In Summary_Epharmacy\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1etqrto99N3Tmv9Z-svwa4OtFjUewpP0KwMiflq36hrg\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        df.to_csv('c42_f.csv')\n",
    "        print(\"Google sheet Updated_at\", pd.Timestamp.now())\n",
    "\n",
    "        #Updating In cc_daily_dashboard\n",
    "        gsheet_name = 'CC Daily Order Dashboard' #This google sheet will be updated\n",
    "        tab_name = 'C42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1_ibELjBzTBBjKeNkgsIm5EzrDo5vamHZraOjMjDqNvI\") #Key Of the google sheet - CC order dashboard\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        print(\"CC_Google_sheet Updated_at\", pd.Timestamp.now())\n",
    "\n",
    "\n",
    "        #Updating In Reorder_sheet\n",
    "        gsheet_name = 'Reorder' #This google sheet will be updated\n",
    "        tab_name = 'c42_current_month' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1WBLi5ShCGQ1US-x3OxPT2mXmz8sCn5UxiqtXJ16poBU\") #Key Of the google sheet - CC order dashboard\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        print(\"Reorder_sheet Updated_at\", pd.Timestamp.now())\n",
    "\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error connecting to PostgreSQL:\", error)\n",
    "    finally:# Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "# Schedule the task to run every minute\n",
    "schedule.every().hour.at(\":29\").do(Order_summary_update)\n",
    "#print(schedule.get_jobs())\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "sEojE7-p8_Vz",
    "outputId": "2d8552fb-750a-41a6-bff2-e1bd1662d364"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "No module named 'schedule'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3ec1a74f0cdb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mschedule\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mOrder_summary_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'schedule'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#This script updates old orders data - working till Jan'2025\n",
    "import schedule as schedule\n",
    "import time\n",
    "def Order_summary_update():\n",
    "    try:\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import paramiko\n",
    "        import re\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                        host='127.0.0.1',\n",
    "                        port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                        database='efrprod',\n",
    "                        user='emamireaduser',\n",
    "                        password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "\n",
    "                # Perform database operations here\n",
    "                cursor.execute(\n",
    "                '''\n",
    "                SELECT order_Table.*\n",
    "                ,CASE WHEN\n",
    "                \tod IS NULL THEN 'Not First Order'\n",
    "                \tELSE '1st Order' END AS new_flag\n",
    "                FROM\n",
    "                (SELECT\n",
    "                 osl.order_id\n",
    "                ,o.user_id as created_by_id\n",
    "                ,CASE\n",
    "                \tWHEN o.state =0 THEN 'cart'\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\n",
    "                \tWHEN o.state =14  THEN 'Return_completed'\n",
    "                \tELSE 'In-Progress'\n",
    "                END AS status\n",
    "                ,o.city_id\n",
    "                ,o.delivery_remarks\n",
    "                ,o.payment_method\n",
    "                ,o.auto_completed\n",
    "                ,o.order_total_paise*1.0/100 AS order_value\n",
    "                ,o.shipping_total_paise*1.0/100 AS Shipping_charge\n",
    "                ,o.doctor_names\n",
    "                --,o.delivery_slot_id, o.store_id, o.shipping_address_id, o.billing_address_id\n",
    "                ,osl.confirmed_on\n",
    "                ,CASE\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\n",
    "                \tWHEN osl.channel = 1 THEN 'Mobile'\n",
    "                \tELSE 'Website'\n",
    "                END as channel_name\n",
    "                ,CASE\n",
    "                \tWHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                \tWHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                \tWHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\n",
    "                \tWHEN osl.channel = 1 THEN 'Saathi App'\n",
    "                \tELSE 'Website'\n",
    "                END as channel2\n",
    "                ,CASE\n",
    "                \tWHEN o.state =0 THEN 'cart'\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\n",
    "                \tWHEN o.state =3 THEN 'order_received'\n",
    "                \tWHEN o.state =4 THEN 'shipped'\n",
    "                \tWHEN o.state =5 THEN 'out_for_delivery'\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\n",
    "                \tWHEN o.state =14 THEN 'Return_completed'\n",
    "                \tWHEN o.state =17 THEN 'rescheduled'\n",
    "                \t\tELSE 'In-Progress' END AS detailed_status\n",
    "                ,customer_id\n",
    "                ,users.name AS modified_by\n",
    "                ,w.code AS dc_code\n",
    "                ,DS.slot_description\n",
    "                ,DS.slot_date AS Expected_Delivery\n",
    "                ,DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) AS exp_delivery_start\n",
    "                ,DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) AS exp_delivery_end\n",
    "                ,co.state_changed_on + time '5:30' as cancelled_date\n",
    "                ,co.reason\n",
    "                ,co.remarks\n",
    "                ,CASE\n",
    "                \tWHEN so.modified_by_id = 94098 THEN 'Ecogreen API'\n",
    "                \tWHEN so.modified_by_id = 25 THEN 'Vinculum API'\n",
    "                \tWHEN so.modified_by_id = 44306 THEN 'Delite'\n",
    "                \tWHEN so.modified_by_id = 162007 THEN 'Kumar Rohit'\n",
    "                \tWHEN so.modified_by_id = 175710 THEN 'Arun Kumar'\n",
    "                \tELSE 'Others'END AS shipped_by\n",
    "                ,so.state_changed_on + time '5:30'AS shipped\n",
    "                ,ofd.state_changed_on + time '5:30'AS out_for_delivery\n",
    "                ,del.state_changed_on + time '5:30'AS delivered_date\n",
    "                ,iv.amount_paise/100*1.0 AS invoiced_amt\n",
    "                ,iv.invoiced_at\n",
    "                ,iv.wallet_amount\n",
    "                ,ph.number\n",
    "                ,us.name AS user_name\n",
    "                ,us.created_at AS registration_date\n",
    "                ,us.registration_source\n",
    "                ,areas.pincode\n",
    "                ,ROW_NUMBER() OVER(PARTITION BY o.user_id ORDER BY osl.confirmed_on) AS nth_order\n",
    "                --,CASE WHEN\n",
    "                --\tROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY osl.confirmed_on ASC) = 1\n",
    "                --\tTHEN '1st Order' ELSE 'Not First Order'\n",
    "                --END AS new_flag_month\n",
    "                ,CASE\n",
    "                \t WHEN del.state_changed_on + time '5:30' IS NULL THEN 'Undelivered'\n",
    "                \t WHEN del.state_changed_on + time '5:30'\n",
    "                \t < DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) THEN 'Early'\n",
    "                \t WHEN del.state_changed_on + time '5:30'\n",
    "                \t > DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME)\n",
    "                \t THEN 'Delay'\n",
    "                \t ELSE 'Between Slot'\n",
    "                END AS delivery_flag\n",
    "                FROM\n",
    "                \t(SELECT\n",
    "                \torder_id\n",
    "                \t,MAX(modified_by_id) modified_by_id\n",
    "                \t,MAX(channel) channel\n",
    "                \t,MAX(state_changed_on + time '5:30') AS confirmed_on\n",
    "                \tFROM order_status_logs\n",
    "                \tWHERE state_changed_on >'2024-12-31 18:30' AND to_state = 3\n",
    "                \tGROUP BY order_id) AS osl\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\n",
    "                LEFT JOIN users ON users.id = osl.modified_by_id\n",
    "                LEFT JOIN warehouses w ON w.id = o.store_id\n",
    "                LEFT JOIN delivery_slots DS ON o.delivery_slot_id = DS.id\n",
    "                LEFT JOIN order_status_logs co ON co.order_id = osl.order_id AND co.to_state = 7 -- Calcelled Orders\n",
    "                LEFT JOIN order_status_logs so ON so.order_id = osl.order_id AND so.to_state = 4 -- Shipped Orders\n",
    "                LEFT JOIN order_status_logs ofd ON ofd.order_id = osl.order_id AND ofd.to_state = 5 -- out for delivery\n",
    "                LEFT JOIN order_status_logs del ON del.order_id = osl.order_id AND del.to_state = 6 -- out for delivery\n",
    "                LEFT JOIN invoices iv ON iv.order_id = osl.order_id\n",
    "                LEFT JOIN phones ph ON ph.user_id = o.user_id AND ph.deleted_at IS NULL\n",
    "                LEFT JOIN users us ON us.id = o.user_id\n",
    "                LEFT JOIN addresses ON addresses.id = o.shipping_address_id --to Get the area id\n",
    "                LEFT JOIN areas ON areas.id = addresses.area_id\n",
    "                ORDER BY osl.confirmed_on DESC) as order_Table\n",
    "                LEFT JOIN\n",
    "                (SELECT od FROM\n",
    "                (SELECT ord.*,\n",
    "                ROW_NUMBER() OVER (PARTITION BY ord.user_id ORDER BY ord.confirmed_on) AS order_number\n",
    "                FROM\n",
    "                (\n",
    "                SELECT\n",
    "                order_id as od\n",
    "                ,MAX(u.created_at) as registered_at\n",
    "                ,MAX(o.user_id) as user_id\n",
    "                ,MAX(state_changed_on + time '5:30') as confirmed_on\n",
    "                ,MAX(channel) as channel\n",
    "                ,MAX(modified_by_id) as modified_by\n",
    "                FROM order_status_logs osl\n",
    "                LEFT JOIN orders o on o.id = osl.order_id\n",
    "                LEFT JOIN users u on u.id = o.user_id\n",
    "                WHERE to_state = 3 and state_changed_on > '2023-01-31 18:30:00'\n",
    "                GROUP BY od\n",
    "                ) AS ord)\n",
    "                AS ordr\n",
    "                WHERE order_number = 1\n",
    "                AND COALESCE(registered_at, '1970-01-01') >= CURRENT_DATE - INTERVAL '12 MONTH'\n",
    "                --AND EXTRACT(MONTH FROM confirmed_on) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "                AND confirmed_on >= '2024-12-31 18:30:00'\n",
    "                --AND EXTRACT(YEAR FROM confirmed_on) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "                ) as first_order\n",
    "                on first_order.od = order_Table.order_id\n",
    "                order by order_Table.confirmed_on DESC\n",
    "                ''')\n",
    "\n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description] # Get column names from cursor description\n",
    "                df = pd.DataFrame(records, columns=columns) # Convert records to DataFrame\n",
    "                df = df[['order_id', 'created_by_id', 'status', 'city_id', 'delivery_remarks',\n",
    "                 'payment_method', 'new_flag', 'order_value', 'shipping_charge',\n",
    "                 'detailed_status', 'out_for_delivery', 'confirmed_on', 'channel_name',\n",
    "                 'shipped', 'dc_code', 'slot_description', 'expected_delivery',\n",
    "                 'modified_by', 'reason', 'remarks', 'cancelled_date',\n",
    "                 'delivered_date', 'channel2', 'invoiced_amt', 'shipped_by',\n",
    "                 'exp_delivery_start', 'exp_delivery_end', 'delivery_flag', 'number', 'user_name','pincode','registration_date']]\n",
    "                print(\"Data fetched and saved to df\")\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            print(\"Error connecting to PostgreSQL:\", error)\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "        gsheet_name = 'Summary_Epharmacy' #This google sheet will be updated\n",
    "        tab_name = 'C42_Combined' # This particular tab is to be updated\n",
    "\n",
    "        #Updating In Summary_Epharmacy\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1etqrto99N3Tmv9Z-svwa4OtFjUewpP0KwMiflq36hrg\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        df.to_csv('c42_f.csv')\n",
    "        print(\"Google sheet Updated_at\", pd.Timestamp.now())\n",
    "\n",
    "        #Updating In cc_daily_dashboard\n",
    "        gsheet_name = 'CC Daily Order Dashboard' #This google sheet will be updated\n",
    "        tab_name = 'C42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1_ibELjBzTBBjKeNkgsIm5EzrDo5vamHZraOjMjDqNvI\") #Key Of the google sheet - CC order dashboard\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        print(\"CC_Google_sheet Updated_at\", pd.Timestamp.now())\n",
    "\n",
    "\n",
    "        #Updating In Reorder_sheet\n",
    "        gsheet_name = 'Reorder' #This google sheet will be updated\n",
    "        tab_name = 'c42_current_month' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1WBLi5ShCGQ1US-x3OxPT2mXmz8sCn5UxiqtXJ16poBU\") #Key Of the google sheet - CC order dashboard\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        print(\"Reorder_sheet Updated_at\", pd.Timestamp.now())\n",
    "\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error connecting to PostgreSQL:\", error)\n",
    "    finally:# Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "# Schedule the task to run every minute\n",
    "schedule.every().hour.at(\":00\").do(Order_summary_update)\n",
    "#print(schedule.get_jobs())\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhqLMc6N9fGF",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Sales report Backup At : 5th Feb2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sale update in CC_Dashboard- Added logging and threading\n",
    "# Updated_at : 5th March'25 : to change date\n",
    "\n",
    "import schedule\n",
    "import time\n",
    "import threading\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"log_sales.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "job_running = threading.Lock()\n",
    "\n",
    "def line_items_sales():\n",
    "    if not job_running.acquire(blocking=False):\n",
    "        logging.warning(\"Job is already running, skipping this execution.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Job started.\")\n",
    "        connection = None  # Initialize connection to None at the start\n",
    "        cursor = None  # Initialize cursor as None as well\n",
    "        \n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                    host='127.0.0.1',\n",
    "                    port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                    database='efrprod',\n",
    "                    user='emamireaduser',\n",
    "                    password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "                \n",
    "                logging.info(\"Fetching item-wise sales data\")\n",
    "                cursor.execute('''\n",
    "                SELECT\n",
    "                line_items.order_id as ord_id,\t\n",
    "                line_items.variant_id,\n",
    "                products.name as product_name,\t\n",
    "                categories.name as category,\n",
    "                line_items.quantity,\t\n",
    "                line_items.mrp_paise * 1.0 / 100 as MRP,\t\n",
    "                line_items.sales_price_paise * 1.0 / 100 as Sales_price,\t\n",
    "                line_items.total_paise * 1.0 / 100 as Total_Price,\t\n",
    "                line_items.discount_amount_paise * 1.0 / 100 as Discount,\n",
    "                --osl.modified_by_id,\n",
    "                users.name as modified_by,\n",
    "                CASE \n",
    "                    WHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                    WHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                    WHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                    WHEN osl.channel = 0 THEN 'Call Center'\n",
    "                    WHEN osl.channel = 1 THEN 'Saathi_App'\n",
    "                    ELSE 'Website'\n",
    "                END as channel,\n",
    "                osl.state_changed_on + time '5:30' as confirmed_on,\n",
    "                CASE \n",
    "                    WHEN o.state = 0 THEN 'cart'\n",
    "                    WHEN o.state = 1 THEN 'pre_checkout'\n",
    "                    WHEN o.state = 2 THEN 'Checkout'\n",
    "                    WHEN o.state = 6 THEN 'Delivered'\n",
    "                    WHEN o.state = 7 THEN 'Cancelled'\n",
    "                    WHEN o.state = 14 THEN 'Return_completed'\n",
    "                    ELSE 'In-Progress' \n",
    "                END as status,\n",
    "                dc.dc_code,\n",
    "                ip.property_value as d_profile,\n",
    "                ip2.property_value as actute_chronic\n",
    "                FROM \n",
    "                line_items \n",
    "                LEFT JOIN variants ON line_items.variant_id = variants.id\t\n",
    "                LEFT JOIN products ON variants.product_id = products.id\t\n",
    "                LEFT JOIN product_types ON products.product_type_id = product_types.id\t\n",
    "                LEFT JOIN categories ON categories.id = product_types.category_id\n",
    "                LEFT JOIN order_status_logs osl ON osl.order_id = line_items.order_id\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\n",
    "                LEFT JOIN distribution_centers dc ON dc.id = o.store_id\n",
    "                LEFT JOIN item_properties ip ON ip.item_id = line_items.variant_id AND ip.property_id IN ('1351')\n",
    "                LEFT JOIN item_properties ip2 ON ip2.item_id = line_items.variant_id AND ip2.property_id IN ('1352')\n",
    "                LEFT JOIN users on users.id = osl.modified_by_id\n",
    "                WHERE \n",
    "                line_items.order_id IN ( \n",
    "                    SELECT order_id \n",
    "                    FROM order_status_logs as ols\n",
    "                    LEFT JOIN orders ON orders.id = ols.order_id\n",
    "                    WHERE \n",
    "                        state_changed_on >= '2025-11-30 18:30:00.000000' \n",
    "                        AND to_state = 3\n",
    "                        AND city_id = 13\n",
    "                )\n",
    "                AND osl.to_state = 3\n",
    "                ORDER BY confirmed_on DESC\n",
    "                ''')\n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description]  # Get column names from cursor description\n",
    "                sales = pd.DataFrame(records, columns=columns)  # Convert records to DataFrame\n",
    "                \n",
    "                logging.info(f\"Fetched {len(records)} records from the database.\")\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            logging.error(f\"Error connecting to PostgreSQL: {error}\")\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                logging.info(\"PostgreSQL connection is closed.\")\n",
    "\n",
    "        # Updating data into Google Sheet\n",
    "        gsheet_name = 'CC Order Dashboard'\n",
    "        tab_name = 'Sales'\n",
    "\n",
    "        def write_df_to_gsheet(gsheet_name, tab_name, sales):\n",
    "            try:\n",
    "                gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "                sh = gc.open_by_key(\"1_ibELjBzTBBjKeNkgsIm5EzrDo5vamHZraOjMjDqNvI\")  # Key of the Google Sheet\n",
    "                worksheet = sh.worksheet(tab_name)\n",
    "                set_with_dataframe(worksheet, sales)\n",
    "                logging.info(f\"Sales data successfully updated in {gsheet_name} Sheet.\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error updating Google Sheet: {e}\")\n",
    "\n",
    "        write_df_to_gsheet(gsheet_name, tab_name, sales)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error in job execution: {e}\")\n",
    "    finally:\n",
    "        job_running.release()\n",
    "        logging.info(\"Job finished.\\n\")\n",
    "\n",
    "# Schedule the job to run every hour at minute 02\n",
    "schedule.every().hour.at(\":03\").do(line_items_sales)\n",
    "logging.info(\"Job scheduled to run every hour.\")\n",
    "\n",
    "# Main loop to keep the scheduler running\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)  # Check for scheduled jobs every 60 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hxll7x8fy2E"
   },
   "outputs": [],
   "source": [
    "# Sale update in CC_Dashboard- Added logging and threading : Backup At : 5th Feb2025\n",
    "import schedule\n",
    "import time\n",
    "import threading\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"log_sales.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "job_running = threading.Lock()\n",
    "\n",
    "def line_items_sales():\n",
    "    if not job_running.acquire(blocking=False):\n",
    "        logging.warning(\"Job is already running, skipping this execution.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Job started.\")\n",
    "        connection = None  # Initialize connection to None at the start\n",
    "        cursor = None  # Initialize cursor as None as well\n",
    "\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                    host='127.0.0.1',\n",
    "                    port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                    database='efrprod',\n",
    "                    user='emamireaduser',\n",
    "                    password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "\n",
    "                # Fetching item-wise sales data\n",
    "                cursor.execute('''\n",
    "                SELECT\n",
    "                line_items.order_id as ord_id,\n",
    "                line_items.variant_id,\n",
    "                products.name as product_name,\n",
    "                categories.name as category,\n",
    "                line_items.quantity,\n",
    "                line_items.mrp_paise * 1.0 / 100 as MRP,\n",
    "                line_items.sales_price_paise * 1.0 / 100 as Sales_price,\n",
    "                line_items.total_paise * 1.0 / 100 as Total_Price,\n",
    "                line_items.discount_amount_paise * 1.0 / 100 as Discount,\n",
    "                --osl.modified_by_id,\n",
    "                users.name as modified_by,\n",
    "                CASE\n",
    "                    WHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                    WHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                    WHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                    WHEN osl.channel = 0 THEN 'Call Center'\n",
    "                    WHEN osl.channel = 1 THEN 'Saathi_App'\n",
    "                    ELSE 'Website'\n",
    "                END as channel,\n",
    "                osl.state_changed_on + time '5:30' as confirmed_on,\n",
    "                CASE\n",
    "                    WHEN o.state = 0 THEN 'cart'\n",
    "                    WHEN o.state = 1 THEN 'pre_checkout'\n",
    "                    WHEN o.state = 2 THEN 'Checkout'\n",
    "                    WHEN o.state = 6 THEN 'Delivered'\n",
    "                    WHEN o.state = 7 THEN 'Cancelled'\n",
    "                    WHEN o.state = 14 THEN 'Return_completed'\n",
    "                    ELSE 'In-Progress'\n",
    "                END as status,\n",
    "                dc.dc_code,\n",
    "                ip.property_value as d_profile,\n",
    "                ip2.property_value as actute_chronic\n",
    "                FROM\n",
    "                line_items\n",
    "                LEFT JOIN variants ON line_items.variant_id = variants.id\n",
    "                LEFT JOIN products ON variants.product_id = products.id\n",
    "                LEFT JOIN product_types ON products.product_type_id = product_types.id\n",
    "                LEFT JOIN categories ON categories.id = product_types.category_id\n",
    "                LEFT JOIN order_status_logs osl ON osl.order_id = line_items.order_id\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\n",
    "                LEFT JOIN distribution_centers dc ON dc.id = o.store_id\n",
    "                LEFT JOIN item_properties ip ON ip.item_id = line_items.variant_id AND ip.property_id IN ('1351')\n",
    "                LEFT JOIN item_properties ip2 ON ip2.item_id = line_items.variant_id AND ip2.property_id IN ('1352')\n",
    "                LEFT JOIN users on users.id = osl.modified_by_id\n",
    "                WHERE\n",
    "                line_items.order_id IN (\n",
    "                    SELECT order_id\n",
    "                    FROM order_status_logs as ols\n",
    "                    LEFT JOIN orders ON orders.id = ols.order_id\n",
    "                    WHERE\n",
    "                        state_changed_on >= '2024-12-31 18:30:00.000000'\n",
    "                        AND to_state = 3\n",
    "                        AND city_id = 13\n",
    "                )\n",
    "                AND osl.to_state = 3\n",
    "                ORDER BY confirmed_on DESC\n",
    "                ''')\n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description]  # Get column names from cursor description\n",
    "                sales = pd.DataFrame(records, columns=columns)  # Convert records to DataFrame\n",
    "\n",
    "                logging.info(f\"Fetched {len(records)} records from the database.\")\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            logging.error(f\"Error connecting to PostgreSQL: {error}\")\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                logging.info(\"PostgreSQL connection is closed.\")\n",
    "\n",
    "        # Updating data into Google Sheet\n",
    "        gsheet_name = 'CC Order Dashboard'\n",
    "        tab_name = 'Sales'\n",
    "\n",
    "        def write_df_to_gsheet(gsheet_name, tab_name, sales):\n",
    "            try:\n",
    "                gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "                sh = gc.open_by_key(\"1_ibELjBzTBBjKeNkgsIm5EzrDo5vamHZraOjMjDqNvI\")  # Key of the Google Sheet\n",
    "                worksheet = sh.worksheet(tab_name)\n",
    "                set_with_dataframe(worksheet, sales)\n",
    "                logging.info(f\"Sales data successfully updated in {gsheet_name} Sheet.\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error updating Google Sheet: {e}\")\n",
    "\n",
    "        write_df_to_gsheet(gsheet_name, tab_name, sales)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error in job execution: {e}\")\n",
    "    finally:\n",
    "        job_running.release()\n",
    "        logging.info(\"Job finished.\\n\")\n",
    "\n",
    "# Schedule the job to run every hour at minute 02\n",
    "schedule.every().hour.at(\":03\").do(line_items_sales)\n",
    "logging.info(\"Job scheduled to run every hour.\")\n",
    "\n",
    "# Main loop to keep the scheduler running\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)  # Check for scheduled jobs every 60 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6EtKZ8rKjaD"
   },
   "outputs": [],
   "source": [
    "# Sale update in CC_Dashboard- Added logging and threading : old\n",
    "import schedule\n",
    "import time\n",
    "import threading\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import psycopg2\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"sales_log.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "job_running = threading.Lock()\n",
    "\n",
    "def line_items_sales():\n",
    "    if not job_running.acquire(blocking=False):\n",
    "        logging.warning(\"Job is already running, skipping this execution.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Job started.\")\n",
    "        connection = None  # Initialize connection to None at the start\n",
    "        cursor = None  # Initialize cursor as None as well\n",
    "\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                    host='127.0.0.1',\n",
    "                    port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                    database='efrprod',\n",
    "                    user='emamireaduser',\n",
    "                    password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "\n",
    "                # Fetching item-wise sales data\n",
    "                cursor.execute('''\n",
    "                SELECT\n",
    "                line_items.order_id as ord_id,\n",
    "                line_items.variant_id,\n",
    "                products.name as product_name,\n",
    "                categories.name as category,\n",
    "                line_items.quantity,\n",
    "                line_items.mrp_paise * 1.0 / 100 as MRP,\n",
    "                line_items.sales_price_paise * 1.0 / 100 as Sales_price,\n",
    "                line_items.total_paise * 1.0 / 100 as Total_Price,\n",
    "                line_items.discount_amount_paise * 1.0 / 100 as Discount,\n",
    "                --osl.modified_by_id,\n",
    "                users.name as modified_by,\n",
    "                CASE\n",
    "                    WHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                    WHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                    WHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                    WHEN osl.channel = 0 THEN 'Call Center'\n",
    "                    WHEN osl.channel = 1 THEN 'Saathi_App'\n",
    "                    ELSE 'Website'\n",
    "                END as channel,\n",
    "                osl.state_changed_on + time '5:30' as confirmed_on,\n",
    "                CASE\n",
    "                    WHEN o.state = 0 THEN 'cart'\n",
    "                    WHEN o.state = 1 THEN 'pre_checkout'\n",
    "                    WHEN o.state = 2 THEN 'Checkout'\n",
    "                    WHEN o.state = 6 THEN 'Delivered'\n",
    "                    WHEN o.state = 7 THEN 'Cancelled'\n",
    "                    WHEN o.state = 14 THEN 'Return_completed'\n",
    "                    ELSE 'In-Progress'\n",
    "                END as status,\n",
    "                dc.dc_code,\n",
    "                ip.property_value as d_profile,\n",
    "                ip2.property_value as actute_chronic\n",
    "                FROM\n",
    "                line_items\n",
    "                LEFT JOIN variants ON line_items.variant_id = variants.id\n",
    "                LEFT JOIN products ON variants.product_id = products.id\n",
    "                LEFT JOIN product_types ON products.product_type_id = product_types.id\n",
    "                LEFT JOIN categories ON categories.id = product_types.category_id\n",
    "                LEFT JOIN order_status_logs osl ON osl.order_id = line_items.order_id\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\n",
    "                LEFT JOIN distribution_centers dc ON dc.id = o.store_id\n",
    "                LEFT JOIN item_properties ip ON ip.item_id = line_items.variant_id AND ip.property_id IN ('1351')\n",
    "                LEFT JOIN item_properties ip2 ON ip2.item_id = line_items.variant_id AND ip2.property_id IN ('1352')\n",
    "                LEFT JOIN users on users.id = osl.modified_by_id\n",
    "                WHERE\n",
    "                line_items.order_id IN (\n",
    "                    SELECT order_id\n",
    "                    FROM order_status_logs as ols\n",
    "                    LEFT JOIN orders ON orders.id = ols.order_id\n",
    "                    WHERE\n",
    "                        state_changed_on >= '2024-12-31 18:30:00.000000'\n",
    "                        AND to_state = 3\n",
    "                        AND city_id = 13\n",
    "                )\n",
    "                AND osl.to_state = 3\n",
    "                ORDER BY confirmed_on DESC\n",
    "                ''')\n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description]  # Get column names from cursor description\n",
    "                sales = pd.DataFrame(records, columns=columns)  # Convert records to DataFrame\n",
    "\n",
    "                logging.info(f\"Fetched {len(records)} records from the database.\")\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            logging.error(f\"Error connecting to PostgreSQL: {error}\")\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                logging.info(\"PostgreSQL connection is closed.\")\n",
    "\n",
    "        # Updating data into Google Sheet\n",
    "        gsheet_name = 'CC Order Dashboard'\n",
    "        tab_name = 'Sales'\n",
    "\n",
    "        def write_df_to_gsheet(gsheet_name, tab_name, sales):\n",
    "            try:\n",
    "                gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "                sh = gc.open_by_key(\"1_ibELjBzTBBjKeNkgsIm5EzrDo5vamHZraOjMjDqNvI\")  # Key of the Google Sheet\n",
    "                worksheet = sh.worksheet(tab_name)\n",
    "                set_with_dataframe(worksheet, sales)\n",
    "                logging.info(\"Sales data successfully updated in Google Sheet.\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error updating Google Sheet: {e}\")\n",
    "\n",
    "        write_df_to_gsheet(gsheet_name, tab_name, sales)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error in job execution: {e}\")\n",
    "    finally:\n",
    "        job_running.release()\n",
    "        logging.info(\"Job finished.\\n\")\n",
    "\n",
    "# Schedule the job to run every hour at minute 02\n",
    "schedule.every().hour.at(\":02\").do(line_items_sales)\n",
    "logging.info(\"Job scheduled to run every hour at minute 02.\")\n",
    "\n",
    "# Main loop to keep the scheduler running\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)  # Check for scheduled jobs every 60 seconds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zmUN30fKdML",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Line Items Update Backup At : 14th Feb2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated_at : 5th March to change data\n",
    "#Added Threading, Defined Schedule function\n",
    "import schedule\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import psycopg2\n",
    "import paramiko\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import gspread\n",
    "import numpy as np\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "import logging\n",
    "import threading  # For running the scheduler in the background\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"log_Line_items_update.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def line_items():\n",
    "    connection = None  # Initialize connection to None at the start\n",
    "    cursor = None      # Initialize cursor as None as well\n",
    "    df_rosscare = pd.DataFrame()  # Initialize as empty DataFrame\n",
    "    df_generic = pd.DataFrame()   # Initialize as empty DataFrame\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Job started.\")\n",
    "        with SSHTunnelForwarder(\n",
    "            ('65.1.183.184', 22),\n",
    "            ssh_username='ubuntu',\n",
    "            ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "            remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "            local_bind_address=('localhost', 5432)\n",
    "        ) as tunnel:\n",
    "            # Establish a connection to the RDS PostgreSQL database\n",
    "            connection = psycopg2.connect(\n",
    "                host='127.0.0.1',\n",
    "                port=tunnel.local_bind_port,  # Local port bound to the SSH tunnel\n",
    "                database='efrprod',\n",
    "                user='emamireaduser',\n",
    "                password='emamireadaccess'\n",
    "            )\n",
    "            cursor = connection.cursor()\n",
    "            \n",
    "            # Fetching Item Wise Sales Data for Rosscare\n",
    "            logging.info(\"Fetching rosscare item-wise sales data\")\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                SELECT\n",
    "                   line_items.order_id as ord_id,\t\n",
    "                   line_items.variant_id,\n",
    "                   products.name as product_name,\t\n",
    "                   categories.name as category,\n",
    "                   line_items.quantity,\t\n",
    "                   line_items.mrp_paise * 1.0 / 100 as MRP,\t\n",
    "                   line_items.sales_price_paise * 1.0 / 100 as Sales_price,\t\n",
    "                   line_items.total_paise * 1.0 / 100 as Total_Price,\t\n",
    "                   line_items.discount_amount_paise * 1.0 / 100 as Discount,\n",
    "                   users.name as modified_by,\n",
    "                   CASE \n",
    "                       WHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                       WHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                       WHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) THEN 'Ecom_CC'\n",
    "                       WHEN osl.channel = 0 THEN 'Call Center'\n",
    "                       WHEN osl.channel = 1 THEN 'Saathi_App'\n",
    "                       ELSE 'Website'\n",
    "                   END as channel,\n",
    "                   osl.state_changed_on + Time '5:30' as confirmed_on,\n",
    "                   CASE \n",
    "                       WHEN o.state = 0 THEN 'cart'\n",
    "                       WHEN o.state = 1 THEN 'pre_checkout'\n",
    "                       WHEN o.state = 2 THEN 'Checkout'\n",
    "                       WHEN o.state = 6 THEN 'Delivered'\n",
    "                       WHEN o.state = 7 THEN 'Cancelled'\n",
    "                       WHEN o.state = 14 THEN 'Return_completed'\n",
    "                       ELSE 'In-Progress' \n",
    "                   END as status,\n",
    "                   dc.dc_code,\n",
    "                   ip.property_value as d_profile,\n",
    "                   ip2.property_value as actute_chronic\n",
    "                FROM \n",
    "                   line_items \n",
    "                   LEFT JOIN variants ON line_items.variant_id = variants.id\t\n",
    "                   LEFT JOIN products ON variants.product_id = products.id\t\n",
    "                   LEFT JOIN product_types ON products.product_type_id = product_types.id\t\n",
    "                   LEFT JOIN categories ON categories.id = product_types.category_id\n",
    "                   LEFT JOIN order_status_logs osl ON osl.order_id = line_items.order_id\n",
    "                   LEFT JOIN orders o ON o.id = osl.order_id\n",
    "                   LEFT JOIN distribution_centers dc ON dc.id = o.store_id\n",
    "                   LEFT JOIN item_properties ip ON ip.item_id = line_items.variant_id AND ip.property_id IN ('1351')\n",
    "                   LEFT JOIN item_properties ip2 ON ip2.item_id = line_items.variant_id AND ip2.property_id IN ('1352')\n",
    "                   LEFT JOIN users ON users.id = osl.modified_by_id\n",
    "                WHERE \n",
    "                   line_items.order_id IN (\n",
    "                       SELECT order_id \n",
    "                       FROM order_status_logs as ols\n",
    "                       LEFT JOIN orders ON orders.id = ols.order_id\n",
    "                       WHERE \n",
    "                           state_changed_on >= '2024-10-31 18:30:00.000000' \n",
    "                           AND to_state = 3\n",
    "                           AND city_id = 13\n",
    "                   )\n",
    "                   AND osl.to_state = 3\n",
    "                   AND Variant_id in\n",
    "                   (\n",
    "                    35521,34399,36121,23363,23813,46601,52563,31312,42309,44329,33980,47540,30672,52651,52577,\n",
    "                    35949,34764,36122,36131,44359,44539,52595,42307,42310,42315,30643,47549,30673,52641,52578,\n",
    "                    35514,34765,36123,18276,34766,45505,31309,44368,44326,44330,30644,47550,23191,52646,52579,\n",
    "                    35517,1460,36124,18277,34767,30585,23188,41250,42311,44371,30645,47551,30674,52611,52582,\n",
    "                    35515,23808,23362,18278,36130,48976,23189,35518,42312,44331,30646,47552,30678,52653,52591,\n",
    "                    35952,34757,36125,18279,34761,50084,23190,44332,42313,33979,30647,47558,30679,52648,52583,\n",
    "                    43846,4342,34770,36132,34771,50592,30659,23270,42314,44370,43784,47559,30677,52639,52592,\n",
    "                    44475,2918,33660,33918,43841,50816,30660,26881,44327,41249,30648,48356,30680,52612,52584,\n",
    "                    17277,34450,25089,23802,34773,50823,18236,44372,44328,44152,30649,48357,35522,52633,52593,\n",
    "                    17273,34096,31313,30111,44358,50822,34164,34160,35519,44153,30650,48358,35525,51436,52594,\n",
    "                    17271,33788,21562,35524,44357,51682,34163,41256,35516,44154,44375,48363,30669,51437,52636,\n",
    "                    28527,33779,36126,30273,43847,51686,42306,42326,37807,44155,44376,30656,36027,52652,52637,\n",
    "                    29366,3798,23359,34772,44355,51687,30662,44325,37808,41255,44373,30657,52650,52640,52645,\n",
    "                    28529,30253,18139,30274,44537,51683,30661,30664,25620,41253,45187,30658,50836,52649,52794,\n",
    "                    28530,7929,36127,34758,44474,51684,30663,33982,26833,41252,45188,30665,51000,52205,52791,\n",
    "                    28532,6718,36128,34769,47613,51685,35955,34154,30675,41254,44479,30768,50834,52287,52793,\n",
    "                    28533,17282,36129,23812,47614,51562,41251,34155,30676,28366,54050,30666,47736,52570,52803,\n",
    "                    17286,34763,38063,30298,47542,51561,28323,34165,44559,35513,52638,35523,47735,52571,52804,\n",
    "                    17270,34776,26786,34774,47615,52063,33981,43753,44560,35520,51742,30667,51438,52572,52807,\n",
    "                    3794,2930,23366,24337,43848,52064,44369,43752,44561,44374,45242,30668,51430,52574,52829,\n",
    "                    23361,17276,23365,34760,45507,17269,33983,43751,34179,34162,47538,30670,51432,52575,52830,\n",
    "                    36133,36120,23364,34759,45506,17275,42266,42308,35951,44558,47539,30671,52170,52576,52831,\n",
    "                    52832,52833,52835,52836,52837,52838,52839,52840,52841,52842,52843,52844,52845,52846,52847,\n",
    "                    52861,52864,52865,52866,52867,52868,52869,53995,53996,53997,53999,54000,53990,54001,54005,\n",
    "                    54006,54007,53991,53989,54012,54013,54014,54052,54078,54079,53845,53884,53885,53998,53992,\n",
    "                    52870,52871,52913,52914,53022,53109,53175,53190,53191,53192,53399,53688,53719,53843,53844,\n",
    "                    53993,53994,54312,54423,54436,54438,54440,54441,54442,54443,54445\n",
    "                   )\n",
    "                ORDER BY osl.state_changed_on DESC\n",
    "                \"\"\"\n",
    "            )\n",
    "            records = cursor.fetchall()\n",
    "            # Convert records to a DataFrame\n",
    "            df_rosscare = pd.DataFrame(records, columns=[desc[0] for desc in cursor.description])\n",
    "            df_rosscare['day'] = df_rosscare['confirmed_on'].dt.day\n",
    "            df_rosscare['month_name'] = df_rosscare['confirmed_on'].dt.strftime('%b')\n",
    "            logging.info(f\"{len(records)} records fetched from Rosscare sales data\")\n",
    "            \n",
    "            # Fetching Generic Sales Data\n",
    "            logging.info(\"Fetching generic sales data\")\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                SELECT\n",
    "                   line_items.order_id as ord_id,\t\n",
    "                   line_items.variant_id,\n",
    "                   products.name as product_name,\t\n",
    "                   categories.name as category,\n",
    "                   line_items.quantity,\t\n",
    "                   line_items.mrp_paise * 1.0 / 100 as MRP,\t\n",
    "                   line_items.sales_price_paise * 1.0 / 100 as Sales_price,\t\n",
    "                   line_items.total_paise * 1.0 / 100 as Total_Price,\t\n",
    "                   line_items.discount_amount_paise * 1.0 / 100 as Discount,\n",
    "                   users.name as modified_by,\n",
    "                   CASE \n",
    "                       WHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                       WHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                       WHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) THEN 'Ecom_CC'\n",
    "                       WHEN osl.channel = 0 THEN 'Call Center'\n",
    "                       WHEN osl.channel = 1 THEN 'Saathi_App'\n",
    "                       ELSE 'Website'\n",
    "                   END as channel,\n",
    "                   osl.state_changed_on + Time '5:30' as confirmed_on,\n",
    "                   CASE \n",
    "                       WHEN o.state = 0 THEN 'cart'\n",
    "                       WHEN o.state = 1 THEN 'pre_checkout'\n",
    "                       WHEN o.state = 2 THEN 'Checkout'\n",
    "                       WHEN o.state = 6 THEN 'Delivered'\n",
    "                       WHEN o.state = 7 THEN 'Cancelled'\n",
    "                       WHEN o.state = 14 THEN 'Return_completed'\n",
    "                       ELSE 'In-Progress' \n",
    "                   END as status,\n",
    "                   dc.dc_code,\n",
    "                   ip.property_value as d_profile,\n",
    "                   ip2.property_value as actute_chronic\n",
    "                FROM \n",
    "                   line_items \n",
    "                   LEFT JOIN variants ON line_items.variant_id = variants.id\t\n",
    "                   LEFT JOIN products ON variants.product_id = products.id\t\n",
    "                   LEFT JOIN product_types ON products.product_type_id = product_types.id\t\n",
    "                   LEFT JOIN categories ON categories.id = product_types.category_id\n",
    "                   LEFT JOIN order_status_logs osl ON osl.order_id = line_items.order_id\n",
    "                   LEFT JOIN orders o ON o.id = osl.order_id\n",
    "                   LEFT JOIN distribution_centers dc ON dc.id = o.store_id\n",
    "                   LEFT JOIN item_properties ip ON ip.item_id = line_items.variant_id AND ip.property_id IN ('1351')\n",
    "                   LEFT JOIN item_properties ip2 ON ip2.item_id = line_items.variant_id AND ip2.property_id IN ('1352')\n",
    "                   LEFT JOIN users ON users.id = osl.modified_by_id\n",
    "                WHERE \n",
    "                   line_items.order_id IN (\n",
    "                       SELECT order_id \n",
    "                       FROM order_status_logs as ols\n",
    "                       LEFT JOIN orders ON orders.id = ols.order_id\n",
    "                       WHERE \n",
    "                           state_changed_on >= '2024-10-31 18:30:00.000000' \n",
    "                           AND to_state = 3\n",
    "                           AND city_id = 13\n",
    "                   )\n",
    "                   AND osl.to_state = 3\n",
    "                   AND Variant_id in\n",
    "                   (\n",
    "                       21861,46497,51039,51748,52272,51925,52129,53336,53260,53697,21974,53939,54181,46466,53507,49021,53782,51787,\n",
    "                       47267,46476,50852,47140,52273,51823,53409,53511,53253,53698,53922,53781,54182,53377,46719,53532,53500,53463,\n",
    "                       46749,46692,52279,46831,52274,52262,52550,53215,53496,22656,53923,53266,54183,46511,52547,54140,47984,53492,\n",
    "                       46488,22469,51226,46716,51781,51988,52537,53334,44619,53699,53924,45245,54184,50864,52538,53382,54144,53380,\n",
    "                       47852,44922,36881,46743,51849,51854,53394,53339,46478,53700,48789,16684,53913,53408,53898,53383,53907,53340,\n",
    "                       47164,46756,48139,46474,52259,52014,53374,53338,47780,53701,53925,53940,54185,52368,46869,53518,46968,53527,\n",
    "                       47811,46826,22275,45653,52258,53690,53327,53337,30001,51378,53926,10070,22734,53379,53503,53514,53464,53345,\n",
    "                       50888,46525,22276,46485,52260,52275,53329,2787,40104,53702,53927,17207,40709,53389,53822,22780,46914,52303,\n",
    "                       22903,46526,22382,49546,52146,52276,53691,30256,53693,53703,53928,54169,45691,51780,46846,46492,53497,47800,\n",
    "                       47532,47258,51747,46731,51945,52277,53513,30329,46167,53704,53227,50884,54186,50516,34257,47250,52544,46501,\n",
    "                       50899,46535,50649,47097,52261,52278,53324,46694,47518,47702,21742,53508,49391,54146,54136,53352,46633,17110,\n",
    "                       49892,51188,22902,46898,52181,51930,53325,53311,46753,46676,53929,46867,31300,53499,46734,53385,46823,53354,\n",
    "                       46463,46899,50995,47341,52192,51881,53328,53265,17371,11516,53930,53454,52316,52533,54137,53378,53375,37290,\n",
    "                       44720,46464,51965,36576,51828,51800,53189,53520,53502,43886,53931,48249,52246,53370,53900,54141,25759,53521,\n",
    "                       50860,50855,50683,51069,52263,52282,51339,53515,42103,53705,53932,47088,52236,53501,53505,54142,53793,32967,\n",
    "                       46536,51329,53689,46687,52264,52280,53692,5558,53694,53706,53933,47122,54187,53462,48142,40049,54145,53314,\n",
    "                       46703,50928,40436,52267,52265,52281,47481,53316,53695,53919,53934,46748,54188,53355,53343,40050,53371,46523,\n",
    "                       22415,51409,51744,52268,52180,50865,52099,53274,53696,53707,53935,54170,53546,50677,21935,54143,53387,46482,\n",
    "                       47465,50937,51745,52269,52202,50667,53456,53273,22201,53708,53936,54171,46529,50724,54138,46951,53470,47760,\n",
    "                       51746,22205,51715,52270,52266,51799,53335,53263,22202,53920,53937,50550,46917,53369,54139,53268,50847,53533,\n",
    "                       22008,51138,46487,52271,52232,51852,48102,53262,46738,53921,53938,53482,52384,51037,40075,50915,53384,53512,\n",
    "                       53906,54199,53441,53911,52294,53905,54200,54201,53388,53381,53903,54202,54203,53780,53902,54204,54205,46908,\n",
    "                       54207,29979,49728,45243,17298,29588,53814,53784,54208,54209,54210,40363,54211,31299,54212,53473,53528,54213,\n",
    "                       47206,53447,39960,54217,52178,54218,46534,34488,22246,46159,40501,47235,48188,22095,46807,46484,12636,54219,\n",
    "                       54220,50499,48127,47083,52305,47624,49009,49207,40500,52251,40062,50076,54221,52315,46832,46837,47755,46531,\n",
    "                       47052,54223,50491,22247,53264,52007,53530,54224,46889,54225,46669,50732,25544,53411,12352,46841,51008,54226,\n",
    "                       52127,47872,34213,44536,40559,54228,46887,53258,22232,46480,54229,54230,49220,54231,47891,47100,54232,48247,\n",
    "                       47767,54235,40061,46900,46521,53310,47149,50401,54236,22916,21523,54237,54238,54239,47591,47462,54240,52559,\n",
    "                       54242,50185,50737,54243,46886,54244,47006,48640,46772,46465,53419,47240,52385,22151,54245,46727,53765,51242,\n",
    "                       51012,54247,51856,38331,46891,54248,46518,47520,39956,54249,39837,54250,22414,54251,46726,54252,47273,46840,\n",
    "                       22936,52553,46827,51146,47561,48467,50851,46502,47287,54163,53487,46517,46682,53396,46499,46507,22937,54168,\n",
    "                       54147,17217,46677,47268,50977,43273,51052,54148,54156,54164,52186,47660,51814,54191,54151,46508,22471,50739,\n",
    "                       52301,46520,52179,47876,54172,46721,54189,43530,47688,54165,40298,52365,47999,53272,54152,40361,54166,52546,\n",
    "                       53766,53517,54158,40139,54173,46481,53498,46715,54157,46522,53912,46693,53516,54192,46892,54206,39669,47032,\n",
    "                       47139,54153,54159,47506,54174,46754,54190,54149,47973,21884,39948,53522,51307,54193,54214,23224,54215,53519,\n",
    "                       40499,53779,54160,46956,46822,46675,53890,22141,21864,44535,47272,54175,52239,54194,46751,48191,53386,52244,\n",
    "                       53313,54154,54161,54167,37607,46746,53914,54150,47064,22234,40079,54176,52047,54195,47274,54222,22804,52310,\n",
    "                       21873,54155,54162,22782,47582,45633,53445,21347,46472,22236,39965,54177,53819,54196,54246,46765,22012,37511,\n",
    "                       47042,53220,48195,22783,46683,53524,53908,47603,22901,46515,48217,54178,51119,22132,52256,47432,46763,47484,\n",
    "                       54179,46543,46856,52293,47601,46717,54227,22946,50890,54197,21875,21883,47777,53483,46777,53904,7453,50350,\n",
    "                       53910,48145,54233,49562,48332,54234,47499,48672,50845,50907,54216,40703,54253,47602,53915,51376,46630,22569,\n",
    "                       54180,46834,47752,46568,48670,54241,47085,46572,50853,54198,53766,47139,40499,53313,21873,47042,54179,53910,\n",
    "                       44720,46488,49892,47852,46536,46703,46463,47811,47532,22415,47267,46749,47465,51746,22903,22936,54147,52301,\n",
    "                       54180,53906,50888,50899,54207,47206,54220,47052,52127,47767,54242,51012,50860,22008,47164,54324,54325,54326,\n",
    "                       54327,54328,54329,54330,54331,54332,48974,54333,46912,54334,54335,54336,54337,54338,52188,54339,46475,48605,\n",
    "                       47106,40253,54340,53562,54341,53878,53233,46875,53234,54342,54343,54344,51180,54345,52311,47145,54346,54347,\n",
    "                       50714,52420,54348,54349,54350,54351,54352,54353,54354,22133,54355,54356,54357,34219,50908,50886,46052,54358,\n",
    "                       54359,54360,54361,54362,54363,54364,54365,54366,54367,54368,52383,54369,54370,54371,50711,52378,53322,53326,\n",
    "                       47129,52409,47241,48028,54372,54373,54374,54375,54376,53315,22094,50862,52292,54377,46865,54378,54379,49447,\n",
    "                       54380,54381,54382,45932,54383,54384,46708,54385,54386,22378,54387,22175,54388,54389,54390,54391,46933,54392,\n",
    "                       53261,54393,54394,47306,54395,54396,54397,54398,54399,54400,54401,54402,54403,54404,54405,54406,54407,54408,\n",
    "                       54409,54410,54411,54412,54413,50974,54414,54415,54416,54417,54418\n",
    "                   )\n",
    "                ORDER BY osl.state_changed_on DESC\n",
    "                \"\"\"\n",
    "            )\n",
    "            records = cursor.fetchall()\n",
    "            # Convert records to a DataFrame\n",
    "            df_generic = pd.DataFrame(records, columns=[desc[0] for desc in cursor.description])\n",
    "            df_generic['day'] = df_generic['confirmed_on'].dt.day\n",
    "            df_generic['month_name'] = df_generic['confirmed_on'].dt.strftime('%b')\n",
    "            logging.info(f\"{len(records)} records fetched from generic sales data\")\n",
    "            \n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        logging.error(f\"Error connecting to PostgreSQL: {error}\")\n",
    "    finally:\n",
    "        # Close the database connection if it was opened\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            logging.info(\"PostgreSQL connection is closed\")\n",
    "    \n",
    "    # Function to update a given DataFrame to a specified Google Sheets tab\n",
    "    def write_df_to_gsheet(gsheet_name, tab_name, df):\n",
    "        gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "        sh = gc.open_by_key(\"1FRgKGBPXjg1mjncLsohsKmc9DGIqQZyDZSx6T5qy1ds\")\n",
    "        worksheet = sh.worksheet(tab_name)\n",
    "        set_with_dataframe(worksheet, df)\n",
    "        \n",
    "\n",
    "    # Update Rosscare data\n",
    "    gsheet_name = 'Automation data'\n",
    "    tab_name = 'Rosscare'\n",
    "    logging.info(f\"Updating rosscare sales data in {gsheet_name}\")\n",
    "    write_df_to_gsheet(gsheet_name, tab_name, df_rosscare)\n",
    "    logging.info(\"Rosscare data updated\")\n",
    "    # Update Generic data\n",
    "    tab_name = 'Generic'\n",
    "    logging.info(f\"Updating generic sales data in {gsheet_name}\")\n",
    "    write_df_to_gsheet(gsheet_name, tab_name, df_generic)\n",
    "    logging.info(\"Generic data updated\\n\")\n",
    "\n",
    "# Schedule the job to run every hour at the 31st minute\n",
    "schedule.every().hour.at(\":50\").do(line_items)\n",
    "logging.info(\"Scheduling task to run every hour\")\n",
    "\n",
    "# Define a function to run the scheduler in a background thread\n",
    "def run_scheduler():\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(5)  # Check every 5 seconds\n",
    "\n",
    "# Start the scheduler thread (as a daemon so it stops when you close the Notebook)\n",
    "scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)\n",
    "scheduler_thread.start()\n",
    "\n",
    "logging.info(\"Scheduler is running in the background. Check your log file for updates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p628ygTRY-E4"
   },
   "outputs": [],
   "source": [
    "#Updated at : 14th feb 2025 -logging configured\n",
    "import schedule\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import psycopg2\n",
    "import paramiko\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import gspread\n",
    "import numpy as np\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename = \"log_Line_items_update.txt\",\n",
    "    level = logging.INFO,\n",
    "    format = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def line_items():\n",
    "    connection = None  # Initialize connection to None at the start\n",
    "    cursor = None  # Initialize cursor as None as well\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Job started.\")\n",
    "        with SSHTunnelForwarder(\n",
    "            ('65.1.183.184', 22),\n",
    "            ssh_username='ubuntu',\n",
    "            ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "            remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "            local_bind_address=('localhost', 5432)\n",
    "        ) as tunnel:\n",
    "            # Establish a connection to the RDS PostgreSQL database\n",
    "            connection = psycopg2.connect(\n",
    "                host='127.0.0.1',\n",
    "                port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                database='efrprod',\n",
    "                user='emamireaduser',\n",
    "                password='emamireadaccess'\n",
    "            )\n",
    "            cursor = connection.cursor()\n",
    "             #Fetching Item Wise Sales Data all categories\n",
    "            logging.info(\"Fetching rosscare item-wise sales data\")\n",
    "            cursor.execute(\n",
    "           \"\"\"\n",
    "            SELECT\n",
    "           line_items.order_id as ord_id,\n",
    "           line_items.variant_id,\n",
    "           products.name as product_name,\n",
    "           categories.name as category,\n",
    "           line_items.quantity,\n",
    "           line_items.mrp_paise * 1.0 / 100 as MRP,\n",
    "           line_items.sales_price_paise * 1.0 / 100 as Sales_price,\n",
    "           line_items.total_paise * 1.0 / 100 as Total_Price,\n",
    "           line_items.discount_amount_paise * 1.0 / 100 as Discount,\n",
    "           --osl.modified_by_id,\n",
    "           users.name as modified_by,\n",
    "           CASE\n",
    "               WHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "               WHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "               WHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "               WHEN osl.channel = 0 THEN 'Call Center'\n",
    "               WHEN osl.channel = 1 THEN 'Saathi_App'\n",
    "               ELSE 'Website'\n",
    "           END as channel,\n",
    "           osl.state_changed_on + Time '5:30' as confirmed_on,\n",
    "           CASE\n",
    "               WHEN o.state = 0 THEN 'cart'\n",
    "               WHEN o.state = 1 THEN 'pre_checkout'\n",
    "               WHEN o.state = 2 THEN 'Checkout'\n",
    "               WHEN o.state = 6 THEN 'Delivered'\n",
    "               WHEN o.state = 7 THEN 'Cancelled'\n",
    "               WHEN o.state = 14 THEN 'Return_completed'\n",
    "               ELSE 'In-Progress'\n",
    "           END as status,\n",
    "           dc.dc_code,\n",
    "           ip.property_value as d_profile,\n",
    "           ip2.property_value as actute_chronic\n",
    "           FROM\n",
    "           line_items\n",
    "           LEFT JOIN variants ON line_items.variant_id = variants.id\n",
    "           LEFT JOIN products ON variants.product_id = products.id\n",
    "           LEFT JOIN product_types ON products.product_type_id = product_types.id\n",
    "           LEFT JOIN categories ON categories.id = product_types.category_id\n",
    "           LEFT JOIN order_status_logs osl ON osl.order_id = line_items.order_id\n",
    "           LEFT JOIN orders o ON o.id = osl.order_id\n",
    "           LEFT JOIN distribution_centers dc ON dc.id = o.store_id\n",
    "           LEFT JOIN item_properties ip ON ip.item_id = line_items.variant_id AND ip.property_id IN ('1351')\n",
    "           LEFT JOIN item_properties ip2 ON ip2.item_id = line_items.variant_id AND ip2.property_id IN ('1352')\n",
    "           left JOIn users on users.id = osl.modified_by_id\n",
    "           WHERE\n",
    "           line_items.order_id IN (\n",
    "               SELECT order_id\n",
    "               FROM order_status_logs as ols\n",
    "               LEFT JOIN orders ON orders.id = ols.order_id\n",
    "               WHERE\n",
    "                   state_changed_on >= '2024-09-30 18:30:00.000000'\n",
    "                   AND to_state = 3\n",
    "                   AND city_id = 13\n",
    "           )\n",
    "           AND osl.to_state = 3\n",
    "           AND Variant_id in\n",
    "           (\n",
    "            35521\t,34399\t,36121\t,23363\t,23813\t,46601\t,52563\t,31312\t,42309\t,44329\t,33980\t,47540\t,30672\t,52651\t,52577\n",
    "            ,35949\t,34764\t,36122\t,36131\t,44359\t,44539\t,52595\t,42307\t,42310\t,42315\t,30643\t,47549\t,30673\t,52641\t,52578\n",
    "            ,35514\t,34765\t,36123\t,18276\t,34766\t,45505\t,31309\t,44368\t,44326\t,44330\t,30644\t,47550\t,23191\t,52646\t,52579\n",
    "            ,35517\t,1460\t,36124\t,18277\t,34767\t,30585\t,23188\t,41250\t,42311\t,44371\t,30645\t,47551\t,30674\t,52611\t,52582\n",
    "            ,35515\t,23808\t,23362\t,18278\t,36130\t,48976\t,23189\t,35518\t,42312\t,44331\t,30646\t,47552\t,30678\t,52653\t,52591\n",
    "            ,35952\t,34757\t,36125\t,18279\t,34761\t,50084\t,23190\t,44332\t,42313\t,33979\t,30647\t,47558\t,30679\t,52648\t,52583\n",
    "            ,43846\t,4342\t,34770\t,36132\t,34771\t,50592\t,30659\t,23270\t,42314\t,44370\t,43784\t,47559\t,30677\t,52639\t,52592\n",
    "            ,44475\t,2918\t,33660\t,33918\t,43841\t,50816\t,30660\t,26881\t,44327\t,41249\t,30648\t,48356\t,30680\t,52612\t,52584\n",
    "            ,17277\t,34450\t,25089\t,23802\t,34773\t,50823\t,18236\t,44372\t,44328\t,44152\t,30649\t,48357\t,35522\t,52633\t,52593\n",
    "            ,17273\t,34096\t,31313\t,30111\t,44358\t,50822\t,34164\t,34160\t,35519\t,44153\t,30650\t,48358\t,35525\t,51436\t,52594\n",
    "            ,17271\t,33788\t,21562\t,35524\t,44357\t,51682\t,34163\t,41256\t,35516\t,44154\t,44375\t,48363\t,30669\t,51437\t,52636\n",
    "            ,28527\t,33779\t,36126\t,30273\t,43847\t,51686\t,42306\t,42326\t,37807\t,44155\t,44376\t,30656\t,36027\t,52652\t,52637\n",
    "            ,29366\t,3798\t,23359\t,34772\t,44355\t,51687\t,30662\t,44325\t,37808\t,41255\t,44373\t,30657\t,52650\t,52640\t,52645\n",
    "            ,28529\t,30253\t,18139\t,30274\t,44537\t,51683\t,30661\t,30664\t,25620\t,41253\t,45187\t,30658\t,50836\t,52649\t,52794\n",
    "            ,28530\t,7929\t,36127\t,34758\t,44474\t,51684\t,30663\t,33982\t,26833\t,41252\t,45188\t,30665\t,51000\t,52205\t,52791\n",
    "            ,28532\t,6718\t,36128\t,34769\t,47613\t,51685\t,35955\t,34154\t,30675\t,41254\t,44479\t,30768\t,50834\t,52287\t,52793\n",
    "            ,28533\t,17282\t,36129\t,23812\t,47614\t,51562\t,41251\t,34155\t,30676\t,28366\t,54050\t,30666\t,47736\t,52570\t,52803\n",
    "            ,17286\t,34763\t,38063\t,30298\t,47542\t,51561\t,28323\t,34165\t,44559\t,35513\t,52638\t,35523\t,47735\t,52571\t,52804\n",
    "            ,17270\t,34776\t,26786\t,34774\t,47615\t,52063\t,33981\t,43753\t,44560\t,35520\t,51742\t,30667\t,51438\t,52572\t,52807\n",
    "            ,3794\t,2930\t,23366\t,24337\t,43848\t,52064\t,44369\t,43752\t,44561\t,44374\t,45242\t,30668\t,51430\t,52574\t,52829\n",
    "            ,23361\t,17276\t,23365\t,34760\t,45507\t,17269\t,33983\t,43751\t,34179\t,34162\t,47538\t,30670\t,51432\t,52575\t,52830\n",
    "            ,36133\t,36120\t,23364\t,34759\t,45506\t,17275\t,42266\t,42308\t,35951\t,44558\t,47539\t,30671\t,52170\t,52576\t,52831\n",
    "            ,52832\t,52833\t,52835\t,52836\t,52837\t,52838\t,52839\t,52840\t,52841\t,52842\t,52843\t,52844\t,52845\t,52846\t,52847\n",
    "            ,52861\t,52864\t,52865\t,52866\t,52867\t,52868\t,52869\t,53995\t,53996\t,53997\t,53999\t,54000\t,53990\t,54001\t,54005\n",
    "            ,54006\t,54007\t,53991\t,53989\t,54012\t,54013\t,54014\t,54052\t,54078\t,54079\t,53845\t,53884\t,53885\t,53998\t,53992\n",
    "            ,52870\t,52871\t,52913\t,52914\t,53022\t,53109\t,53175\t,53190\t,53191\t,53192\t,53399\t,53688\t,53719\t,53843\t,53844\n",
    "            ,53993\t,53994\t,54312\t,54423\t,54436\t,54438\t,54440\t,54441\t,54442\t,54443\t,54445\t\t\t\t)\n",
    "\n",
    "           order by osl.state_changed_on desc\n",
    "           \"\"\"\n",
    "\n",
    "           )\n",
    "            records = cursor.fetchall()\n",
    "            # Convert to DataFrame instead of writing to a CSV file\n",
    "            df_rosscare = pd.DataFrame(records, columns=[desc[0] for desc in cursor.description])\n",
    "            df_rosscare['day'] = df_rosscare['confirmed_on'].dt.day\n",
    "            df_rosscare['month_name'] = df_rosscare['confirmed_on'].dt.strftime('%b')\n",
    "            logging.info(f\"{len(records)} fetched from sales data\")\n",
    "            logging.info(\"Fetching generic sales data\")\n",
    "            cursor.execute(\n",
    "           \"\"\"\n",
    "            SELECT\n",
    "           line_items.order_id as ord_id,\n",
    "           line_items.variant_id,\n",
    "           products.name as product_name,\n",
    "           categories.name as category,\n",
    "           line_items.quantity,\n",
    "           line_items.mrp_paise * 1.0 / 100 as MRP,\n",
    "           line_items.sales_price_paise * 1.0 / 100 as Sales_price,\n",
    "           line_items.total_paise * 1.0 / 100 as Total_Price,\n",
    "           line_items.discount_amount_paise * 1.0 / 100 as Discount,\n",
    "           --osl.modified_by_id,\n",
    "           users.name as modified_by,\n",
    "           CASE\n",
    "               WHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "               WHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "               WHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "               WHEN osl.channel = 0 THEN 'Call Center'\n",
    "               WHEN osl.channel = 1 THEN 'Saathi_App'\n",
    "               ELSE 'Website'\n",
    "           END as channel,\n",
    "           osl.state_changed_on + Time '5:30' as confirmed_on,\n",
    "           CASE\n",
    "               WHEN o.state = 0 THEN 'cart'\n",
    "               WHEN o.state = 1 THEN 'pre_checkout'\n",
    "               WHEN o.state = 2 THEN 'Checkout'\n",
    "               WHEN o.state = 6 THEN 'Delivered'\n",
    "               WHEN o.state = 7 THEN 'Cancelled'\n",
    "               WHEN o.state = 14 THEN 'Return_completed'\n",
    "               ELSE 'In-Progress'\n",
    "           END as status,\n",
    "           dc.dc_code,\n",
    "           ip.property_value as d_profile,\n",
    "           ip2.property_value as actute_chronic\n",
    "           FROM\n",
    "           line_items\n",
    "           LEFT JOIN variants ON line_items.variant_id = variants.id\n",
    "           LEFT JOIN products ON variants.product_id = products.id\n",
    "           LEFT JOIN product_types ON products.product_type_id = product_types.id\n",
    "           LEFT JOIN categories ON categories.id = product_types.category_id\n",
    "           LEFT JOIN order_status_logs osl ON osl.order_id = line_items.order_id\n",
    "           LEFT JOIN orders o ON o.id = osl.order_id\n",
    "           LEFT JOIN distribution_centers dc ON dc.id = o.store_id\n",
    "           LEFT JOIN item_properties ip ON ip.item_id = line_items.variant_id AND ip.property_id IN ('1351')\n",
    "           LEFT JOIN item_properties ip2 ON ip2.item_id = line_items.variant_id AND ip2.property_id IN ('1352')\n",
    "           left JOIn users on users.id = osl.modified_by_id\n",
    "           WHERE\n",
    "           line_items.order_id IN (\n",
    "               SELECT order_id\n",
    "               FROM order_status_logs as ols\n",
    "               LEFT JOIN orders ON orders.id = ols.order_id\n",
    "               WHERE\n",
    "                   state_changed_on >= '2024-09-30 18:30:00.000000'\n",
    "                   AND to_state = 3\n",
    "                   AND city_id = 13\n",
    "           )\n",
    "           AND osl.to_state = 3\n",
    "           AND Variant_id in\n",
    "           (\n",
    "               21861,46497\t,51039\t,51748\t,52272\t,51925\t,52129\t,53336\t,53260\t,53697\t,21974\t,53939\t,54181\t,46466\t,53507\t,49021\t,53782\t,51787\n",
    "            ,47267\t,46476\t,50852\t,47140\t,52273\t,51823\t,53409\t,53511\t,53253\t,53698\t,53922\t,53781\t,54182\t,53377\t,46719\t,53532\t,53500\t,53463\n",
    "            ,46749\t,46692\t,52279\t,46831\t,52274\t,52262\t,52550\t,53215\t,53496\t,22656\t,53923\t,53266\t,54183\t,46511\t,52547\t,54140\t,47984\t,53492\n",
    "            ,46488\t,22469\t,51226\t,46716\t,51781\t,51988\t,52537\t,53334\t,44619\t,53699\t,53924\t,45245\t,54184\t,50864\t,52538\t,53382\t,54144\t,53380\n",
    "            ,47852\t,44922\t,36881\t,46743\t,51849\t,51854\t,53394\t,53339\t,46478\t,53700\t,48789\t,16684\t,53913\t,53408\t,53898\t,53383\t,53907\t,53340\n",
    "            ,47164\t,46756\t,48139\t,46474\t,52259\t,52014\t,53374\t,53338\t,47780\t,53701\t,53925\t,53940\t,54185\t,52368\t,46869\t,53518\t,46968\t,53527\n",
    "            ,47811\t,46826\t,22275\t,45653\t,52258\t,53690\t,53327\t,53337\t,30001\t,51378\t,53926\t,10070\t,22734\t,53379\t,53503\t,53514\t,53464\t,53345\n",
    "            ,50888\t,46525\t,22276\t,46485\t,52260\t,52275\t,53329\t,2787\t,40104\t,53702\t,53927\t,17207\t,40709\t,53389\t,53822\t,22780\t,46914\t,52303\n",
    "            ,22903\t,46526\t,22382\t,49546\t,52146\t,52276\t,53691\t,30256\t,53693\t,53703\t,53928\t,54169\t,45691\t,51780\t,46846\t,46492\t,53497\t,47800\n",
    "            ,47532\t,47258\t,51747\t,46731\t,51945\t,52277\t,53513\t,30329\t,46167\t,53704\t,53227\t,50884\t,54186\t,50516\t,34257\t,47250\t,52544\t,46501\n",
    "            ,50899\t,46535\t,50649\t,47097\t,52261\t,52278\t,53324\t,46694\t,47518\t,47702\t,21742\t,53508\t,49391\t,54146\t,54136\t,53352\t,46633\t,17110\n",
    "            ,49892\t,51188\t,22902\t,46898\t,52181\t,51930\t,53325\t,53311\t,46753\t,46676\t,53929\t,46867\t,31300\t,53499\t,46734\t,53385\t,46823\t,53354\n",
    "            ,46463\t,46899\t,50995\t,47341\t,52192\t,51881\t,53328\t,53265\t,17371\t,11516\t,53930\t,53454\t,52316\t,52533\t,54137\t,53378\t,53375\t,37290\n",
    "            ,44720\t,46464\t,51965\t,36576\t,51828\t,51800\t,53189\t,53520\t,53502\t,43886\t,53931\t,48249\t,52246\t,53370\t,53900\t,54141\t,25759\t,53521\n",
    "            ,50860\t,50855\t,50683\t,51069\t,52263\t,52282\t,51339\t,53515\t,42103\t,53705\t,53932\t,47088\t,52236\t,53501\t,53505\t,54142\t,53793\t,32967\n",
    "            ,46536\t,51329\t,53689\t,46687\t,52264\t,52280\t,53692\t,5558\t,53694\t,53706\t,53933\t,47122\t,54187\t,53462\t,48142\t,40049\t,54145\t,53314\n",
    "            ,46703\t,50928\t,40436\t,52267\t,52265\t,52281\t,47481\t,53316\t,53695\t,53919\t,53934\t,46748\t,54188\t,53355\t,53343\t,40050\t,53371\t,46523\n",
    "            ,22415\t,51409\t,51744\t,52268\t,52180\t,50865\t,52099\t,53274\t,53696\t,53707\t,53935\t,54170\t,53546\t,50677\t,21935\t,54143\t,53387\t,46482\n",
    "            ,47465\t,50937\t,51745\t,52269\t,52202\t,50667\t,53456\t,53273\t,22201\t,53708\t,53936\t,54171\t,46529\t,50724\t,54138\t,46951\t,53470\t,47760\n",
    "            ,51746\t,22205\t,51715\t,52270\t,52266\t,51799\t,53335\t,53263\t,22202\t,53920\t,53937\t,50550\t,46917\t,53369\t,54139\t,53268\t,50847\t,53533\n",
    "            ,22008\t,51138\t,46487\t,52271\t,52232\t,51852\t,48102\t,53262\t,46738\t,53921\t,53938\t,53482\t,52384\t,51037\t,40075\t,50915\t,53384\t,53512\n",
    "            ,53906\t,54199\t,53441\t,53911\t,52294\t,53905\t,54200\t,54201\t,53388\t,53381\t,53903\t,54202\t,54203\t,53780\t,53902\t,54204\t,54205\t,46908\n",
    "            ,54207\t,29979\t,49728\t,45243\t,17298\t,29588\t,53814\t,53784\t,54208\t,54209\t,54210\t,40363\t,54211\t,31299\t,54212\t,53473\t,53528\t,54213\n",
    "            ,47206\t,53447\t,39960\t,54217\t,52178\t,54218\t,46534\t,34488\t,22246\t,46159\t,40501\t,47235\t,48188\t,22095\t,46807\t,46484\t,12636\t,54219\n",
    "            ,54220\t,50499\t,48127\t,47083\t,52305\t,47624\t,49009\t,49207\t,40500\t,52251\t,40062\t,50076\t,54221\t,52315\t,46832\t,46837\t,47755\t,46531\n",
    "            ,47052\t,54223\t,50491\t,22247\t,53264\t,52007\t,53530\t,54224\t,46889\t,54225\t,46669\t,50732\t,25544\t,53411\t,12352\t,46841\t,51008\t,54226\n",
    "            ,52127\t,47872\t,34213\t,44536\t,40559\t,54228\t,46887\t,53258\t,22232\t,46480\t,54229\t,54230\t,49220\t,54231\t,47891\t,47100\t,54232\t,48247\n",
    "            ,47767\t,54235\t,40061\t,46900\t,46521\t,53310\t,47149\t,50401\t,54236\t,22916\t,21523\t,54237\t,54238\t,54239\t,47591\t,47462\t,54240\t,52559\n",
    "            ,54242\t,50185\t,50737\t,54243\t,46886\t,54244\t,47006\t,48640\t,46772\t,46465\t,53419\t,47240\t,52385\t,22151\t,54245\t,46727\t,53765\t,51242\n",
    "            ,51012\t,54247\t,51856\t,38331\t,46891\t,54248\t,46518\t,47520\t,39956\t,54249\t,39837\t,54250\t,22414\t,54251\t,46726\t,54252\t,47273\t,46840\n",
    "            ,22936\t,52553\t,46827\t,51146\t,47561\t,48467\t,50851\t,46502\t,47287\t,54163\t,53487\t,46517\t,46682\t,53396\t,46499\t,46507\t,22937\t,54168\n",
    "            ,54147\t,17217\t,46677\t,47268\t,50977\t,43273\t,51052\t,54148\t,54156\t,54164\t,52186\t,47660\t,51814\t,54191\t,54151\t,46508\t,22471\t,50739\n",
    "            ,52301\t,46520\t,52179\t,47876\t,54172\t,46721\t,54189\t,43530\t,47688\t,54165\t,40298\t,52365\t,47999\t,53272\t,54152\t,40361\t,54166\t,52546\n",
    "            ,53766\t,53517\t,54158\t,40139\t,54173\t,46481\t,53498\t,46715\t,54157\t,46522\t,53912\t,46693\t,53516\t,54192\t,46892\t,54206\t,39669\t,47032\n",
    "            ,47139\t,54153\t,54159\t,47506\t,54174\t,46754\t,54190\t,54149\t,47973\t,21884\t,39948\t,53522\t,51307\t,54193\t,54214\t,23224\t,54215\t,53519\n",
    "            ,40499\t,53779\t,54160\t,46956\t,46822\t,46675\t,53890\t,22141\t,21864\t,44535\t,47272\t,54175\t,52239\t,54194\t,46751\t,48191\t,53386\t,52244\n",
    "            ,53313\t,54154\t,54161\t,54167\t,37607\t,46746\t,53914\t,54150\t,47064\t,22234\t,40079\t,54176\t,52047\t,54195\t,47274\t,54222\t,22804\t,52310\n",
    "            ,21873\t,54155\t,54162\t,22782\t,47582\t,45633\t,53445\t,21347\t,46472\t,22236\t,39965\t,54177\t,53819\t,54196\t,54246\t,46765\t,22012\t,37511\n",
    "            ,47042\t,53220\t,48195\t,22783\t,46683\t,53524\t,53908\t,47603\t,22901\t,46515\t,48217\t,54178\t,51119\t,22132\t,52256\t,47432\t,46763\t,47484\n",
    "            ,54179\t,46543\t,46856\t,52293\t,47601\t,46717\t,54227\t,22946\t,50890\t,54197\t,21875\t,21883\t,47777\t,53483\t,46777\t,53904\t,7453\t,50350\n",
    "            ,53910\t,48145\t,54233\t,49562\t,48332\t,54234\t,47499\t,48672\t,50845\t,50907\t,54216\t,40703\t,54253\t,47602\t,53915\t,51376\t,46630\t,22569\n",
    "            ,54180\t,46834\t,47752\t,46568\t,48670\t,54241\t,47085\t,46572\t,50853\t,54198\t,53766\t,47139\t,40499\t,53313\t,21873\t,47042\t,54179\t,53910\n",
    "            ,44720\t,46488\t,49892\t,47852\t,46536\t,46703\t,46463\t,47811\t,47532\t,22415\t,47267\t,46749\t,47465\t,51746\t,22903\t,22936\t,54147\t,52301\n",
    "            ,54180\t,53906\t,50888\t,50899\t,54207\t,47206\t,54220\t,47052\t,52127\t,47767\t,54242\t,51012\t,50860\t,22008\t,47164\t,54324\t,54325\t,54326\n",
    "            ,54327\t,54328\t,54329\t,54330\t,54331\t,54332\t,48974\t,54333\t,46912\t,54334\t,54335\t,54336\t,54337\t,54338\t,52188\t,54339\t,46475\t,48605\n",
    "            ,47106\t,40253\t,54340\t,53562\t,54341\t,53878\t,53233\t,46875\t,53234\t,54342\t,54343\t,54344\t,51180\t,54345\t,52311\t,47145\t,54346\t,54347\n",
    "            ,50714\t,52420\t,54348\t,54349\t,54350\t,54351\t,54352\t,54353\t,54354\t,22133\t,54355\t,54356\t,54357\t,34219\t,50908\t,50886\t,46052\t,54358\n",
    "            ,54359\t,54360\t,54361\t,54362\t,54363\t,54364\t,54365\t,54366\t,54367\t,54368\t,52383\t,54369\t,54370\t,54371\t,50711\t,52378\t,53322\t,53326\n",
    "            ,47129\t,52409\t,47241\t,48028\t,54372\t,54373\t,54374\t,54375\t,54376\t,53315\t,22094\t,50862\t,52292\t,54377\t,46865\t,54378\t,54379\t,49447\n",
    "            ,54380\t,54381\t,54382\t,45932\t,54383\t,54384\t,46708\t,54385\t,54386\t,22378\t,54387\t,22175\t,54388\t,54389\t,54390\t,54391\t,46933\t,54392\n",
    "            ,53261\t,54393\t,54394\t,47306\t,54395\t,54396\t,54397\t,54398\t,54399\t,54400\t,54401\t,54402\t,54403\t,54404\t,54405\t,54406\t,54407\t,54408\n",
    "            ,54409\t,54410\t,54411\t,54412\t,54413\t,50974\t,54414\t,54415\t,54416\t,54417\t,54418\n",
    "           )\n",
    "           order by osl.state_changed_on desc\n",
    "           \"\"\"\n",
    "\n",
    "           )\n",
    "\n",
    "            records = cursor.fetchall()\n",
    "            # Convert to DataFrame instead of writing to a CSV file\n",
    "            df_generic = pd.DataFrame(records, columns=[desc[0] for desc in cursor.description])\n",
    "            df_generic['day'] = df_generic['confirmed_on'].dt.day\n",
    "            df_generic['month_name'] = df_generic['confirmed_on'].dt.strftime('%b')\n",
    "            logging.info(f\"{len(records)} fetched from sales data\")\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        logging.info(f\"Error connecting to PostgreSQL: {error}\")\n",
    "    finally:\n",
    "        # Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            logging.info(f\"PostgreSQL connection is closed\")\n",
    "\n",
    "    # Updating Data into Automation Sheet Rosscare Tab\n",
    "    gsheet_name = 'Automation data' #This google sheet will be updated\n",
    "    tab_name = 'Rosscare' # This particular tab is to be updated\n",
    "    def write_df_to_gsheet (gsheet_name,tab_name,df_rosscare):\n",
    "        gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "        sh = gc.open_by_key(\"1FRgKGBPXjg1mjncLsohsKmc9DGIqQZyDZSx6T5qy1ds\") #Key Of the google sheet - Automation data\n",
    "        worksheet = sh.worksheet(tab_name)\n",
    "        set_with_dataframe(worksheet,df_rosscare)\n",
    "        logging.info(f\"{tab_name} Updated\")\n",
    "    logging.info(f\"updating rosscare sales data in {gsheet_name}\")\n",
    "    write_df_to_gsheet(gsheet_name,tab_name,df_rosscare)\n",
    "    print(\"Rosscare Updated_at\", pd.Timestamp.now())\n",
    "\n",
    "    # Updating Data into Automation Sheet Generic Tab\n",
    "    gsheet_name = 'Automation data' #This google sheet will be updated\n",
    "    tab_name = 'Generic' # This particular tab is to be updated\n",
    "    def write_df_to_gsheet (gsheet_name,tab_name,df_generic):\n",
    "        gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "        sh = gc.open_by_key(\"1FRgKGBPXjg1mjncLsohsKmc9DGIqQZyDZSx6T5qy1ds\") #Key Of the google sheet - Automation data\n",
    "        worksheet = sh.worksheet(tab_name)\n",
    "        set_with_dataframe(worksheet,df_generic)\n",
    "        logging.info(f\"{tab_name} Updated\\n\")\n",
    "    logging.info(f\"updating generic sales data in {gsheet_name}\")\n",
    "    write_df_to_gsheet(gsheet_name,tab_name,df_generic)\n",
    "\n",
    "\n",
    "\n",
    "schedule.every().hour.at(\":04\").do(line_items)\n",
    "logging.info(\"Scheduling Task to run Everuy hour\")\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJoANfB-9arK",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Bounce Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SekA8yP9dmz"
   },
   "outputs": [],
   "source": [
    "import schedule as schedule\n",
    "import time\n",
    "def bounce_order_report():\n",
    "    try:\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "        import pandas as pd\n",
    "        import paramiko\n",
    "        import re\n",
    "        import schedule\n",
    "        import time\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                        host='127.0.0.1',\n",
    "                        port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                        database='efrprod',\n",
    "                        user='emamireaduser',\n",
    "                        password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "\n",
    "                # Perform database operations here\n",
    "                cursor.execute(\n",
    "        '''\n",
    "\n",
    "        SELECT\n",
    "        Bounce_tbl.order_id,\n",
    "        Bounce_tbl.status,\n",
    "        Bounce_tbl.sku,\n",
    "        Bounce_tbl.name,\n",
    "        ord_qty.order_qty,\n",
    "        Bounce_tbl.deficit_quantity,\n",
    "        Bounce_tbl.Level_1_store,\n",
    "        Bounce_tbl.pincode,\n",
    "        Bounce_tbl.confirmed_on\n",
    "        FROM\n",
    "        (with cte_bounce_orders as (\n",
    "        SELECT\n",
    "            o.order_id,\n",
    "            CASE\n",
    "        \t\tWHEN orders.state =0 THEN 'cart'\n",
    "        \t\tWHEN orders.state =1 THEN 'pre_checkout'\n",
    "        \t\tWHEN orders.state =2 THEN 'Checkout'\n",
    "        \t\tWHEN orders.state =6 THEN 'Delivered'\n",
    "        \t\tWHEN orders.state =7 THEN 'Cancelled'\n",
    "        \t\tWHEN orders.state =14  THEN 'Return_completed'\n",
    "        \t\tELSE 'In-Progress'\n",
    "        \t\tEND AS status,\n",
    "            v.sku,\n",
    "            v.name,\n",
    "            o.deficit_quantity,\n",
    "            w.store_name AS Level_1_store,\n",
    "            ar.pincode,\n",
    "            ols.state_changed_on + INTERVAL '5 hours 30 minutes' AS confirmed_on,\n",
    "        \tCONCAT (o.order_id,v.sku) as order_fr_code,\n",
    "            CASE\n",
    "        \tWHEN orders.customer_id IS NULL AND ols.channel = 1 THEN 'Mobile'\n",
    "        \tWHEN ols.channel = 0 AND COALESCE(orders.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "        \tWHEN ols.channel = 0 THEN 'Call Center'\n",
    "        \tWHEN ols.channel = 1 THEN 'Saathi App'\n",
    "        \tELSE 'Website'\n",
    "        END as channel\n",
    "        FROM\n",
    "            order_deficit_quantity_logs o\n",
    "        LEFT JOIN\n",
    "            warehouses w ON o.warehouse_id = w.id\n",
    "        LEFT JOIN\n",
    "            areas ar ON o.area_id = ar.id\n",
    "        LEFT JOIN\n",
    "            variants v ON v.id = o.variant_id\n",
    "        LEFT JOIN\n",
    "            orders ON orders.id = o.order_id\n",
    "        LEFT JOIN\n",
    "            order_status_logs ols ON ols.order_id = o.order_id\n",
    "        WHERE\n",
    "            ols.to_state = 3\n",
    "            AND ols.state_changed_on > '2024-11-30 18:30:00'\n",
    "            AND orders.state > 2\n",
    "            AND ols.state_changed_on + INTERVAL '5 hours 30 minutes' > '2024-12-31 18:30:00'\n",
    "        )\n",
    "        select * From cte_bounce_orders where confirmed_on > '2024-12-31 18:30:00') Bounce_tbl\n",
    "\n",
    "        left join\n",
    "\n",
    "        (\n",
    "        SELECT\n",
    "        CONCAT (order_id,'FR-',variant_id) as order_fr_code,\n",
    "        quantity as order_qty\n",
    "        FROM line_items where order_id in\n",
    "        (\n",
    "        SELECT\n",
    "        order_id\n",
    "        FROM order_status_logs\n",
    "        WHERE state_changed_on >'2024-12-31 18:30' AND to_state = 3\n",
    "        )) ord_qty\n",
    "        on ord_qty.order_fr_code = Bounce_tbl.order_fr_code\n",
    "\n",
    "        ''')\n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description]  # Get column names from cursor description\n",
    "                bounced_orders = pd.DataFrame(records, columns=columns) # Convert records to DataFrame\n",
    "                bounced_orders.to_csv('bounced_orders.csv')\n",
    "                print(\"Data fetched and saved to bounced_orders.csv\")\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            print(\"Error connecting to PostgreSQL:\", error)\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "\n",
    "        import smtplib\n",
    "        from email.mime.multipart import MIMEMultipart\n",
    "        from email.mime.text import MIMEText\n",
    "        from email.mime.base import MIMEBase\n",
    "        from email import encoders\n",
    "\n",
    "        def send_email(sender_email, sender_password, recipient_emails, cc_emails, subject, message, attachment_filename):\n",
    "            # Construct the email body with signature\n",
    "            body_with_signature = f\"{message}\\n\\nThanks & Regards,\\nKumar Rohit\\nAnalytics Manager | Emami Frank Ross Limited\\n8882041300\\nwww.frankrossphramacy.com\"\n",
    "\n",
    "            # Set up the MIME\n",
    "            msg = MIMEMultipart()\n",
    "            msg['From'] = sender_email\n",
    "            msg['To'] = ', '.join(recipient_emails)\n",
    "            msg['Cc'] = ', '.join(cc_emails) if cc_emails else None\n",
    "            msg['Subject'] = subject\n",
    "\n",
    "            # Add message body\n",
    "            msg.attach(MIMEText(body_with_signature, 'plain'))\n",
    "\n",
    "            # Attach file\n",
    "            with open(attachment_filename, \"rb\") as attachment:\n",
    "                part = MIMEBase(\"application\", \"octet-stream\")\n",
    "                part.set_payload(attachment.read())\n",
    "\n",
    "            encoders.encode_base64(part)\n",
    "            part.add_header(\n",
    "                \"Content-Disposition\",\n",
    "                f\"attachment; filename= {attachment_filename}\",\n",
    "            )\n",
    "            msg.attach(part)\n",
    "\n",
    "            # Connect to the SMTP server\n",
    "            with smtplib.SMTP('smtp-mail.outlook.com', 587) as server:\n",
    "                server.starttls()  # Secure the connection\n",
    "                server.login(sender_email, sender_password)  # Login to your email account\n",
    "                # Combine the recipients and send the email\n",
    "                recipients = recipient_emails + (cc_emails if cc_emails else [])\n",
    "                server.sendmail(sender_email, recipients, msg.as_string())  # Send the email\n",
    "                print(\"Email sent successfully\")\n",
    "\n",
    "        # Set your email credentials and email details\n",
    "        sender_email = 'kumar.rohit@frankrosspharmacy.com'\n",
    "        sender_password = 'Outl00k@0125'\n",
    "        recipient_emails = ['debasish.das@frankrosspharmacy.com']  # List of primary recipients\n",
    "        cc_emails = ['saurabh@frankrosspharmacy.com',\n",
    "        'nitin.vyas@frankrosspharmacy.com','avijit.b@frankrosspharmacy.com','debopam.dey@frankrosspharmacy.com',\n",
    "        'chiradeep.roygupta@frankrosspharmacy.com', 'saurabh@frankrosspharmacy.com','ajatia@frankrosspharmacy.com',\n",
    "        'debtanu.baidya@frankrosspharmacy.com','sarit@frankrosspharmacy.com']\n",
    "        subject = 'Bounced Article List'\n",
    "        message = 'Hi Debasish,\\n\\nPFA excel file containing list of Bounced articles MTD'\n",
    "        attachment_filename = 'bounced_orders.csv'  # Filename of the CSV file\n",
    "\n",
    "        # Call the function to send the email with attachment\n",
    "        send_email(sender_email, sender_password, recipient_emails, cc_emails, subject, message, attachment_filename)\n",
    "        print(\"Updated at\", pd.Timestamp.now())\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error connecting to PostgreSQL:\", error)\n",
    "    finally:# Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "# Schedule the task to run every minute\n",
    "schedule.every().day.at(\"10:15\").do(bounce_order_report)\n",
    "#print(schedule.get_jobs())\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhiKmaFPLBoj",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Cart Abondoned Users :                 Updated at : 11th Feb'2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ed42oEzYER_S"
   },
   "outputs": [],
   "source": [
    "# Configured Logging on 11th Feb and executed\n",
    "\n",
    "import schedule\n",
    "import time\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import paramiko\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"log_cart_abondoned.log\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "def cart_abondoned_orders():\n",
    "    connection = None\n",
    "    cursor = None\n",
    "\n",
    "    try:\n",
    "        logging.info(\" Starting cart_abondoned_orders script...\")\n",
    "\n",
    "        logging.info(\" Establishing SSH Tunnel...\")\n",
    "        with SSHTunnelForwarder(\n",
    "            ('65.1.183.184', 22),\n",
    "            ssh_username='ubuntu',\n",
    "            ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "            remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "            local_bind_address=('localhost', 5432)\n",
    "        ) as tunnel:\n",
    "            logging.info(\" SSH Tunnel established successfully.\")\n",
    "\n",
    "            # Establish PostgreSQL connection\n",
    "            connection = psycopg2.connect(\n",
    "                host='127.0.0.1',\n",
    "                port=tunnel.local_bind_port,\n",
    "                database='efrprod',\n",
    "                user='emamireaduser',\n",
    "                password='emamireadaccess'\n",
    "            )\n",
    "            cursor = connection.cursor()\n",
    "            logging.info(\" Database connection established.\")\n",
    "\n",
    "            # Execute SQL Query\n",
    "            cursor.execute('''\n",
    "            SELECT\n",
    "                o.id as order_id,\n",
    "                o.created_at + time '5:30' as cart_created_at,\n",
    "                o.order_total_paise/100*1.0 as cart_value,\n",
    "                u.name,\n",
    "                ph.number,\n",
    "                ph.otp_verified_at + time '5:30' as cust_registered_date,\n",
    "                EXTRACT(DAY FROM o.created_at) as day\n",
    "            FROM public.orders as o\n",
    "            LEFT JOIN public.order_status_logs as osl\n",
    "                ON osl.order_id = o.id\n",
    "            LEFT JOIN users as u\n",
    "                ON u.id = o.user_id\n",
    "            LEFT JOIN phones as ph\n",
    "                ON ph.user_id = o.user_id\n",
    "            WHERE\n",
    "                EXTRACT(MONTH FROM o.created_at) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "                AND EXTRACT(YEAR FROM o.created_at) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "                AND o.state = 0\n",
    "                AND o.city_id = 13\n",
    "                AND osl.to_state = 0\n",
    "                AND osl.channel IN ('1', '4')\n",
    "            ORDER BY cart_created_at DESC\n",
    "            ''')\n",
    "\n",
    "            # Fetch and process data\n",
    "            records = cursor.fetchall()\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            add_to_cart = pd.DataFrame(records, columns=columns)\n",
    "            logging.info(f\" Data retrieved: {len(add_to_cart)} records.\")\n",
    "\n",
    "        # Save Data to CSV\n",
    "        csv_filename = \"add_to_cart.csv\"\n",
    "        add_to_cart.to_csv(csv_filename, index=False)\n",
    "        logging.info(f\" Data saved to {csv_filename}\")\n",
    "\n",
    "        # Upload data to Google Sheets\n",
    "        def write_df_to_gsheet(gsheet_name, tab_name, df):\n",
    "            try:\n",
    "                logging.info(\" Authenticating Google Sheets API...\")\n",
    "\n",
    "                if not os.path.exists(\"summary-automation-project-fd46b6ab2eba.json\"):\n",
    "                    raise FileNotFoundError(\" Google service account JSON file is missing!\")\n",
    "\n",
    "                gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "                sh = gc.open_by_key(\"14C3k9An4SSyDAWihuXi_IOC4w8wBLSEa574bAmhDZX0\")\n",
    "                worksheet = sh.worksheet(tab_name)\n",
    "                set_with_dataframe(worksheet, df)\n",
    "\n",
    "                logging.info(\" Google Sheet updated successfully.\")\n",
    "            except Exception as gs_error:\n",
    "                logging.error(f\" Google Sheets Error: {gs_error}\")\n",
    "\n",
    "        write_df_to_gsheet(\"Add to Cart Customer Details\", \"Cart_Abondoned_Orders\", add_to_cart)\n",
    "\n",
    "    except Exception as error:\n",
    "        logging.error(f\" Error occurred: {error}\")\n",
    "\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if connection:\n",
    "            connection.close()\n",
    "            logging.info(\" PostgreSQL connection closed.\")\n",
    "\n",
    "\n",
    "# Schedule the task to run at a specific time\n",
    "schedule.every().day.at(\"13:42\").do(cart_abondoned_orders)\n",
    "\n",
    "logging.info(\" Scheduler started. Running every day at 09:30 AM...\")\n",
    "while True:\n",
    "    try:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(5)\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\" Scheduler stopped by user.\")\n",
    "        break\n",
    "    except Exception as loop_error:\n",
    "        logging.error(f\" Scheduler encountered an error: {loop_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNe-_Ysd9yGd"
   },
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import paramiko\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def cart_abondoned_orders():\n",
    "    onnection = None  # Initialize connection to None at the start\n",
    "    cursor = None  # Initialize cursor as None as well\n",
    "    try:\n",
    "        # Create an SSH tunnel to the EC2 instance\n",
    "        with SSHTunnelForwarder(\n",
    "            ('65.1.183.184', 22),\n",
    "            ssh_username='ubuntu',\n",
    "            ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "            remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "            local_bind_address=('localhost', 5432)\n",
    "        ) as tunnel:\n",
    "            # Establish a connection to the RDS PostgreSQL database\n",
    "            connection = psycopg2.connect(\n",
    "                host='127.0.0.1',\n",
    "                port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                database='efrprod',\n",
    "                user='emamireaduser',\n",
    "                password='emamireadaccess'\n",
    "            )\n",
    "            cursor = connection.cursor()\n",
    "\n",
    "            # Perform database operations\n",
    "            cursor.execute('''\n",
    "            SELECT\n",
    "                o.id as order_id,\n",
    "                o.created_at + time '5:30' as cart_created_at,\n",
    "                --o.user_id,\n",
    "                o.order_total_paise/100*1.0 as cart_value,\n",
    "                --o.state,\n",
    "                --osl.channel,\n",
    "                u.name,\n",
    "                ph.number,\n",
    "                ph.otp_verified_at + time '5:30' as cust_registered_date,\n",
    "                EXTRACT(DAY FROM o.created_at) as day\n",
    "            FROM public.orders as o\n",
    "            left join public.order_status_logs as osl\n",
    "            on osl.order_id = o.id\n",
    "            left join users as u\n",
    "            on u.id = o.user_id\n",
    "            left join phones as ph\n",
    "            on ph.user_id = o.user_id\n",
    "            WHERE\n",
    "                EXTRACT(MONTH FROM o.created_at) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "                AND EXTRACT(YEAR FROM o.created_at) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "                AND o.state = 0\n",
    "                AND o.city_id = 13\n",
    "                AND osl.to_state = 0\n",
    "                AND osl.channel in ('1','4')\n",
    "            ORDER BY cart_created_at DESC\n",
    "            ''')\n",
    "            records = cursor.fetchall()\n",
    "            columns = [desc[0] for desc in cursor.description]  # Get column names from cursor description\n",
    "            add_to_cart = pd.DataFrame(records, columns=columns)  # Convert records to DataFrame\n",
    "\n",
    "        # Save the DataFrame to CSV\n",
    "        add_to_cart.to_csv('add_to_cart.csv')\n",
    "        #print(\"sales_data saved at\", pd.Timestamp.now())\n",
    "\n",
    "        # Update Google Sheets\n",
    "        gsheet_name = 'Add to Cart Customer Details'  # Google sheet to be updated\n",
    "        tab_name = 'Cart_Abondoned_Orders'  # Tab to be updated\n",
    "        df = pd.read_csv(\"add_to_cart.csv\")\n",
    "\n",
    "        # Function to write data to Google Sheets\n",
    "        def write_df_to_gsheet(gsheet_name, tab_name, df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"14C3k9An4SSyDAWihuXi_IOC4w8wBLSEa574bAmhDZX0\")  # Key of the Google Sheet\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet, df)\n",
    "\n",
    "        write_df_to_gsheet(gsheet_name, tab_name, df)\n",
    "        #print(\"CC_Google_sheet Updated_at\", pd.Timestamp.now())\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(\"Error occurred:\", error)\n",
    "\n",
    "    finally:\n",
    "        # Ensure the connection is closed if it was successfully opened\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if connection:\n",
    "            connection.close()\n",
    "            print(\"PostgreSQL connection is closed\")\n",
    "\n",
    "\n",
    "# Schedule the task to run every hour at :03\n",
    "schedule.every().day.at(\"09:30\").do(cart_abondoned_orders)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvDBQTtOgHOS",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Four Months Data updated at : 5th feb 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version : 2.01\n",
    "#Updates: added promotion details and updation in new sheet (coupon_performance) started \n",
    "#Updated_at : 5th March 25 : To change the date\n",
    "#This Script Fetches last four Month Data - Order date is hard coded need to be update every month \n",
    "#else it will keep update more than 4 months order data into Reorder sheet \n",
    "\n",
    "# Orders are arranged in ascending order of confirmed on so that older data stays at the top \n",
    "# and newer data gets appended below and doesnot disturb CC Agens Disposition/Remarks\n",
    "\n",
    "import schedule as schedule\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"log_four_month_data.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def four_month_data():\n",
    "    try:\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import paramiko\n",
    "        import re\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                        host='127.0.0.1',\n",
    "                        port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                        database='efrprod',\n",
    "                        user='emamireaduser',\n",
    "                        password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "        \n",
    "                # Perform database operations here\n",
    "                logging.info(\"Executing DB query to fetch orders data\")\n",
    "                cursor.execute(\n",
    "                '''\n",
    "                \t\t\t\tSELECT order_Table.*\n",
    "                ,CASE WHEN\n",
    "                \tod IS NULL THEN 'Not First Order'\n",
    "                \tELSE '1st Order' END AS new_flag\n",
    "                ,CASE\n",
    "                 \tWHEN timeout_at IS NOT NULL THEN 'timeout'\n",
    "                \tWHEN rejected_at IS NOT NULL THEN 'rejected'\n",
    "                \tWHEN accepted_at IS NOT NULL THEN 'accepted'\n",
    "                \tELSE 'pending' end as order_action\n",
    "                ,promo.coupon_code\n",
    "                FROM\n",
    "                (SELECT\t\t\n",
    "                 osl.order_id\t\t\n",
    "                ,o.user_id as created_by_id\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN o.state =0 THEN 'cart'\t\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\t\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\t\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\t\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\t\n",
    "                \tWHEN o.state =14  THEN 'Return_completed'\t\n",
    "                \tELSE 'In-Progress'\t\n",
    "                END AS status\t\t\n",
    "                ,o.city_id\t\t\n",
    "                ,o.delivery_remarks\t\t\n",
    "                ,o.payment_method\t\t\n",
    "                ,o.auto_completed\t\t\n",
    "                ,o.order_total_paise*1.0/100 AS order_value\t\t\n",
    "                ,o.shipping_total_paise*1.0/100 AS Shipping_charge\t\t\n",
    "                ,o.doctor_names\t\t\n",
    "                --,o.delivery_slot_id, o.store_id, o.shipping_address_id, o.billing_address_id\t\t\n",
    "                ,osl.confirmed_on\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\t\n",
    "                \tWHEN osl.channel = 1 THEN 'Mobile'\t\n",
    "                \tELSE 'Website'\t\n",
    "                END as channel_name\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\t\n",
    "                \tWHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                \tWHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\t\n",
    "                \tWHEN osl.channel = 1 THEN 'Saathi App'\t\n",
    "                \tELSE 'Website'\t\n",
    "                END as channel2\t\t\n",
    "                ,CASE \t\t\n",
    "                \tWHEN o.state =0 THEN 'cart'\t\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\t\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\t\n",
    "                \tWHEN o.state =3 THEN 'order_received'\t\n",
    "                \tWHEN o.state =4 THEN 'shipped'\t\n",
    "                \tWHEN o.state =5 THEN 'out_for_delivery'\t\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\t\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\t\n",
    "                \tWHEN o.state =14 THEN 'Return_completed'\t\n",
    "                \tWHEN o.state =17 THEN 'rescheduled'\t\n",
    "                \t\tELSE 'In-Progress' END AS detailed_status\n",
    "                ,customer_id\t\t\n",
    "                ,users.name AS modified_by\t\t\n",
    "                ,w.code AS fulfillment_center\t\n",
    "                ,Wa.code AS Actual_Mapped_Dc\n",
    "                ,DS.slot_description\t\t\n",
    "                ,DS.slot_date AS Expected_Delivery\t\t\n",
    "                ,DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) AS exp_delivery_start\t\t\n",
    "                ,DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) AS exp_delivery_end\t\t\n",
    "                ,co.state_changed_on + time '5:30' as cancelled_date\t\t\n",
    "                ,co.reason\t\t\n",
    "                ,co.remarks\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN so.modified_by_id = 94098 THEN 'Ecogreen API'\t\n",
    "                \tWHEN so.modified_by_id = 25 THEN 'Vinculum API'\t\n",
    "                \tWHEN so.modified_by_id = 44306 THEN 'Delite'\t\n",
    "                \tWHEN so.modified_by_id = 162007 THEN 'Kumar Rohit'\t\n",
    "                \tWHEN so.modified_by_id = 175710 THEN 'Arun Kumar'\t\n",
    "                \tELSE 'Others'END AS shipped_by\t\n",
    "                ,so.state_changed_on + time '5:30'AS shipped\t\t\n",
    "                ,ofd.state_changed_on + time '5:30'AS out_for_delivery\t\t\n",
    "                ,del.state_changed_on + time '5:30'AS delivered_date\t\t\n",
    "                ,iv.amount_paise/100*1.0 AS invoiced_amt\t\t\n",
    "                ,iv.invoiced_at\t\t\n",
    "                ,iv.wallet_amount\t\t\n",
    "                ,ph.number\t\t\n",
    "                ,us.name AS user_name\t\t\n",
    "                ,us.created_at AS registration_date\t\t\n",
    "                ,us.registration_source\t\t\n",
    "                ,areas.pincode\n",
    "                ,op.promotion_id\n",
    "                ,op.promotion_total_paise/100*1.0 as amount_discounted\n",
    "                ,op.cash_back_total_paise/100*1.0 as cashback\n",
    "                --,promo.coupon_code\n",
    "                ,ROW_NUMBER() OVER(PARTITION BY o.user_id ORDER BY osl.confirmed_on) AS nth_order\t\t\n",
    "                --,CASE WHEN \t\t\n",
    "                --\tROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY osl.confirmed_on ASC) = 1\t\n",
    "                --\tTHEN '1st Order' ELSE 'Not First Order'\t\t\n",
    "                --END AS new_flag_month\t\n",
    "                ,CASE \t\t\n",
    "                \t WHEN del.state_changed_on + time '5:30' IS NULL THEN 'Undelivered'\t\t\n",
    "                \t WHEN del.state_changed_on + time '5:30' \t\t\n",
    "                \t < DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) THEN 'Early'\t\n",
    "                \t WHEN del.state_changed_on + time '5:30' \t\t\n",
    "                \t > DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) \t\n",
    "                \t THEN 'Delay'\t\n",
    "                \t ELSE 'Between Slot'\t\t\n",
    "                END AS delivery_flag\n",
    "                ,oah_t.created_at + time '5:30' as timeout_at\n",
    "                ,oah_a.created_at + time '5:30' as accepted_at\n",
    "                ,oah_r.created_at + time '5:30' as rejected_at\n",
    "                \n",
    "                FROM\t\t\n",
    "                \t(SELECT\t\n",
    "                \torder_id\t\n",
    "                \t,MAX(modified_by_id) modified_by_id\t\n",
    "                \t,MAX(channel) channel\t\n",
    "                \t,MAX(state_changed_on + time '5:30') AS confirmed_on\t\n",
    "                \tFROM order_status_logs\t\n",
    "                \tWHERE state_changed_on >'2024-11-30 18:30' AND to_state = 3\t\n",
    "                \tGROUP BY order_id) AS osl\t\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\t\t\n",
    "                LEFT JOIN users ON users.id = osl.modified_by_id\t\t\n",
    "                LEFT JOIN warehouses w ON w.id = o.fulfillment_center_id\n",
    "                LEFT JOIN warehouses wa ON wa.id = o.store_id\n",
    "                LEFT JOIN delivery_slots DS ON o.delivery_slot_id = DS.id\t\t\n",
    "                LEFT JOIN order_status_logs co ON co.order_id = osl.order_id AND co.to_state = 7 -- Calcelled Orders\t\t\n",
    "                LEFT JOIN order_status_logs so ON so.order_id = osl.order_id AND so.to_state = 4 -- Shipped Orders\t\t\n",
    "                LEFT JOIN order_status_logs ofd ON ofd.order_id = osl.order_id AND ofd.to_state = 5 -- out for delivery\t\t\n",
    "                LEFT JOIN order_status_logs del ON del.order_id = osl.order_id AND del.to_state = 6 -- out for delivery\t\t\n",
    "                LEFT JOIN invoices iv ON iv.order_id = osl.order_id\t\t\n",
    "                LEFT JOIN phones ph ON ph.user_id = o.user_id AND ph.deleted_at IS NULL\t\t\n",
    "                LEFT JOIN users us ON us.id = o.user_id \t\t\n",
    "                LEFT JOIN addresses ON addresses.id = o.shipping_address_id --to Get the area id \t\t\n",
    "                LEFT JOIN areas ON areas.id = addresses.area_id\n",
    "                LEFT JOIN order_assignment_histories oah_t on oah_t.order_id = osl.order_id AND oah_t.action = 'time_out'\n",
    "                LEFT JOIN order_assignment_histories oah_a on oah_a.order_id = osl.order_id AND oah_a.action = 'accept'\n",
    "                LEFT JOIN order_assignment_histories oah_r on oah_r.order_id = osl.order_id AND oah_r.action = 'reject'\n",
    "                LEFT JOIN order_promotions op on osl.order_id = op.order_id\n",
    "                ORDER BY osl.confirmed_on DESC) as order_Table\n",
    "                LEFT JOIN \n",
    "                (SELECT od FROM\n",
    "                (SELECT ord.*,\n",
    "                ROW_NUMBER() OVER (PARTITION BY ord.user_id ORDER BY ord.confirmed_on) AS order_number \n",
    "                FROM\n",
    "                (\n",
    "                SELECT \n",
    "                order_id as od\n",
    "                ,MAX(u.created_at) as registered_at\n",
    "                ,MAX(o.user_id) as user_id\n",
    "                ,MAX(state_changed_on + time '5:30') as confirmed_on\n",
    "                ,MAX(channel) as channel\n",
    "                ,MAX(modified_by_id) as modified_by\n",
    "                FROM order_status_logs osl \n",
    "                LEFT JOIN orders o on o.id = osl.order_id\n",
    "                LEFT JOIN users u on u.id = o.user_id\n",
    "                WHERE to_state = 3 and state_changed_on > '2022-12-31 18:30:00'\n",
    "                GROUP BY od\n",
    "                ) AS ord) \n",
    "                AS ordr\n",
    "                WHERE order_number = 1\n",
    "                AND COALESCE(registered_at, '1970-01-01') >= CURRENT_DATE - INTERVAL '12 MONTH'\n",
    "                --AND EXTRACT(MONTH FROM confirmed_on) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "                AND confirmed_on >= '2024-10-31 18:30:00'\n",
    "                --AND EXTRACT(YEAR FROM confirmed_on) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "                ) as first_order\n",
    "                on first_order.od = order_Table.order_id\n",
    "                LEFT JOIN promotions promo on promo.id = order_Table.promotion_id\n",
    "                order by order_Table.confirmed_on\n",
    "  \n",
    "            ''')\n",
    "                \n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description] # Get column names from cursor description\n",
    "                df1 = pd.DataFrame(records, columns=columns) # Convert records to DataFrame\n",
    "                logging.info(f\"{len(records)} records fetched and saved to df\")\n",
    "                df = df1[['order_id', 'created_by_id', 'status', 'city_id', 'delivery_remarks',\n",
    "                         'payment_method', 'new_flag', 'order_value', 'shipping_charge',\n",
    "                         'detailed_status', 'out_for_delivery', 'confirmed_on', 'promotion_id',\n",
    "                         'shipped', 'fulfillment_center', 'slot_description', 'expected_delivery',\n",
    "                         'modified_by', 'reason', 'remarks', 'cancelled_date',\n",
    "                         'delivered_date', 'channel2', 'invoiced_amt', 'shipped_by',\n",
    "                         'exp_delivery_start', 'exp_delivery_end', 'delivery_flag', 'number','user_name' ,'pincode','wallet_amount'\n",
    "                         ,'order_action','actual_mapped_dc','coupon_code']]\n",
    "                logging.info(\"columns re-arranged in df\")\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            logging.info(f\"Error connecting to PostgreSQL : {error}\")\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                logging.info(\"PostgreSQL connection is closed\")\n",
    "        \n",
    "        logging.info(\"started updating Reorder sheet\")\n",
    "        gsheet_name = 'Reorder' #This google sheet will be updated\n",
    "        tab_name = 'C42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1WBLi5ShCGQ1US-x3OxPT2mXmz8sCn5UxiqtXJ16poBU\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f\"{gsheet_name} sheet Updated\")\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        \n",
    "        gsheet_name = 'coupon_performance' #This google sheet will be updated\n",
    "        tab_name = 'c42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1E6r9p8Zn5jB-37kQu1Uu_OolOZocrrgOm2yQOtGJtT4\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f\"{gsheet_name} sheet Updated\")\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "    \n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        logging.info(f'Error connecting to PostgreSQL:{error}')\n",
    "    finally:# Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            logging.info(f'PostgreSQL connection is closed - job finished\\n')\n",
    "\n",
    "logging.info('Schedule the task to run every hour')\n",
    "#schedule.every().hours.at(\":50\").do(four_month_data)\n",
    "schedule.every(2).hours.at(\":30\").do(four_month_data)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version : 2.01\n",
    "#Updates: added promotion details and updation in new sheet (coupon_performance) started \n",
    "#Updated_at : 19th feb 25\n",
    "#This Script Fetches last four Month Data - Order date is hard coded need to be update every month \n",
    "#else it will keep update more than 4 months order data into Reorder sheet \n",
    "\n",
    "# Orders are arranged in ascending order of confirmed on so that older data stays at the top \n",
    "# and newer data gets appended below and doesnot disturb CC Agens Disposition/Remarks\n",
    "\n",
    "import schedule as schedule\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"log_four_month_data.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def four_month_data():\n",
    "    try:\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import paramiko\n",
    "        import re\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                        host='127.0.0.1',\n",
    "                        port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                        database='efrprod',\n",
    "                        user='emamireaduser',\n",
    "                        password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "        \n",
    "                # Perform database operations here\n",
    "                logging.info(\"Executing DB query to fetch orders data\")\n",
    "                cursor.execute(\n",
    "                '''\n",
    "                \t\t\t\tSELECT order_Table.*\n",
    "                ,CASE WHEN\n",
    "                \tod IS NULL THEN 'Not First Order'\n",
    "                \tELSE '1st Order' END AS new_flag\n",
    "                ,CASE\n",
    "                 \tWHEN timeout_at IS NOT NULL THEN 'timeout'\n",
    "                \tWHEN rejected_at IS NOT NULL THEN 'rejected'\n",
    "                \tWHEN accepted_at IS NOT NULL THEN 'accepted'\n",
    "                \tELSE 'pending' end as order_action\n",
    "                ,promo.coupon_code\n",
    "                FROM\n",
    "                (SELECT\t\t\n",
    "                 osl.order_id\t\t\n",
    "                ,o.user_id as created_by_id\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN o.state =0 THEN 'cart'\t\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\t\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\t\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\t\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\t\n",
    "                \tWHEN o.state =14  THEN 'Return_completed'\t\n",
    "                \tELSE 'In-Progress'\t\n",
    "                END AS status\t\t\n",
    "                ,o.city_id\t\t\n",
    "                ,o.delivery_remarks\t\t\n",
    "                ,o.payment_method\t\t\n",
    "                ,o.auto_completed\t\t\n",
    "                ,o.order_total_paise*1.0/100 AS order_value\t\t\n",
    "                ,o.shipping_total_paise*1.0/100 AS Shipping_charge\t\t\n",
    "                ,o.doctor_names\t\t\n",
    "                --,o.delivery_slot_id, o.store_id, o.shipping_address_id, o.billing_address_id\t\t\n",
    "                ,osl.confirmed_on\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\t\n",
    "                \tWHEN osl.channel = 1 THEN 'Mobile'\t\n",
    "                \tELSE 'Website'\t\n",
    "                END as channel_name\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\t\n",
    "                \tWHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                \tWHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\t\n",
    "                \tWHEN osl.channel = 1 THEN 'Saathi App'\t\n",
    "                \tELSE 'Website'\t\n",
    "                END as channel2\t\t\n",
    "                ,CASE \t\t\n",
    "                \tWHEN o.state =0 THEN 'cart'\t\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\t\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\t\n",
    "                \tWHEN o.state =3 THEN 'order_received'\t\n",
    "                \tWHEN o.state =4 THEN 'shipped'\t\n",
    "                \tWHEN o.state =5 THEN 'out_for_delivery'\t\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\t\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\t\n",
    "                \tWHEN o.state =14 THEN 'Return_completed'\t\n",
    "                \tWHEN o.state =17 THEN 'rescheduled'\t\n",
    "                \t\tELSE 'In-Progress' END AS detailed_status\n",
    "                ,customer_id\t\t\n",
    "                ,users.name AS modified_by\t\t\n",
    "                ,w.code AS fulfillment_center\t\n",
    "                ,Wa.code AS Actual_Mapped_Dc\n",
    "                ,DS.slot_description\t\t\n",
    "                ,DS.slot_date AS Expected_Delivery\t\t\n",
    "                ,DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) AS exp_delivery_start\t\t\n",
    "                ,DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) AS exp_delivery_end\t\t\n",
    "                ,co.state_changed_on + time '5:30' as cancelled_date\t\t\n",
    "                ,co.reason\t\t\n",
    "                ,co.remarks\t\t\n",
    "                ,CASE\t\t\n",
    "                \tWHEN so.modified_by_id = 94098 THEN 'Ecogreen API'\t\n",
    "                \tWHEN so.modified_by_id = 25 THEN 'Vinculum API'\t\n",
    "                \tWHEN so.modified_by_id = 44306 THEN 'Delite'\t\n",
    "                \tWHEN so.modified_by_id = 162007 THEN 'Kumar Rohit'\t\n",
    "                \tWHEN so.modified_by_id = 175710 THEN 'Arun Kumar'\t\n",
    "                \tELSE 'Others'END AS shipped_by\t\n",
    "                ,so.state_changed_on + time '5:30'AS shipped\t\t\n",
    "                ,ofd.state_changed_on + time '5:30'AS out_for_delivery\t\t\n",
    "                ,del.state_changed_on + time '5:30'AS delivered_date\t\t\n",
    "                ,iv.amount_paise/100*1.0 AS invoiced_amt\t\t\n",
    "                ,iv.invoiced_at\t\t\n",
    "                ,iv.wallet_amount\t\t\n",
    "                ,ph.number\t\t\n",
    "                ,us.name AS user_name\t\t\n",
    "                ,us.created_at AS registration_date\t\t\n",
    "                ,us.registration_source\t\t\n",
    "                ,areas.pincode\n",
    "                ,op.promotion_id\n",
    "                ,op.promotion_total_paise/100*1.0 as amount_discounted\n",
    "                ,op.cash_back_total_paise/100*1.0 as cashback\n",
    "                --,promo.coupon_code\n",
    "                ,ROW_NUMBER() OVER(PARTITION BY o.user_id ORDER BY osl.confirmed_on) AS nth_order\t\t\n",
    "                --,CASE WHEN \t\t\n",
    "                --\tROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY osl.confirmed_on ASC) = 1\t\n",
    "                --\tTHEN '1st Order' ELSE 'Not First Order'\t\t\n",
    "                --END AS new_flag_month\t\n",
    "                ,CASE \t\t\n",
    "                \t WHEN del.state_changed_on + time '5:30' IS NULL THEN 'Undelivered'\t\t\n",
    "                \t WHEN del.state_changed_on + time '5:30' \t\t\n",
    "                \t < DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) THEN 'Early'\t\n",
    "                \t WHEN del.state_changed_on + time '5:30' \t\t\n",
    "                \t > DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) \t\n",
    "                \t THEN 'Delay'\t\n",
    "                \t ELSE 'Between Slot'\t\t\n",
    "                END AS delivery_flag\n",
    "                ,oah_t.created_at + time '5:30' as timeout_at\n",
    "                ,oah_a.created_at + time '5:30' as accepted_at\n",
    "                ,oah_r.created_at + time '5:30' as rejected_at\n",
    "                \n",
    "                FROM\t\t\n",
    "                \t(SELECT\t\n",
    "                \torder_id\t\n",
    "                \t,MAX(modified_by_id) modified_by_id\t\n",
    "                \t,MAX(channel) channel\t\n",
    "                \t,MAX(state_changed_on + time '5:30') AS confirmed_on\t\n",
    "                \tFROM order_status_logs\t\n",
    "                \tWHERE state_changed_on >'2024-11-30 18:30' AND to_state = 3\t\n",
    "                \tGROUP BY order_id) AS osl\t\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\t\t\n",
    "                LEFT JOIN users ON users.id = osl.modified_by_id\t\t\n",
    "                LEFT JOIN warehouses w ON w.id = o.fulfillment_center_id\n",
    "                LEFT JOIN warehouses wa ON wa.id = o.store_id\n",
    "                LEFT JOIN delivery_slots DS ON o.delivery_slot_id = DS.id\t\t\n",
    "                LEFT JOIN order_status_logs co ON co.order_id = osl.order_id AND co.to_state = 7 -- Calcelled Orders\t\t\n",
    "                LEFT JOIN order_status_logs so ON so.order_id = osl.order_id AND so.to_state = 4 -- Shipped Orders\t\t\n",
    "                LEFT JOIN order_status_logs ofd ON ofd.order_id = osl.order_id AND ofd.to_state = 5 -- out for delivery\t\t\n",
    "                LEFT JOIN order_status_logs del ON del.order_id = osl.order_id AND del.to_state = 6 -- out for delivery\t\t\n",
    "                LEFT JOIN invoices iv ON iv.order_id = osl.order_id\t\t\n",
    "                LEFT JOIN phones ph ON ph.user_id = o.user_id AND ph.deleted_at IS NULL\t\t\n",
    "                LEFT JOIN users us ON us.id = o.user_id \t\t\n",
    "                LEFT JOIN addresses ON addresses.id = o.shipping_address_id --to Get the area id \t\t\n",
    "                LEFT JOIN areas ON areas.id = addresses.area_id\n",
    "                LEFT JOIN order_assignment_histories oah_t on oah_t.order_id = osl.order_id AND oah_t.action = 'time_out'\n",
    "                LEFT JOIN order_assignment_histories oah_a on oah_a.order_id = osl.order_id AND oah_a.action = 'accept'\n",
    "                LEFT JOIN order_assignment_histories oah_r on oah_r.order_id = osl.order_id AND oah_r.action = 'reject'\n",
    "                LEFT JOIN order_promotions op on osl.order_id = op.order_id\n",
    "                ORDER BY osl.confirmed_on DESC) as order_Table\n",
    "                LEFT JOIN \n",
    "                (SELECT od FROM\n",
    "                (SELECT ord.*,\n",
    "                ROW_NUMBER() OVER (PARTITION BY ord.user_id ORDER BY ord.confirmed_on) AS order_number \n",
    "                FROM\n",
    "                (\n",
    "                SELECT \n",
    "                order_id as od\n",
    "                ,MAX(u.created_at) as registered_at\n",
    "                ,MAX(o.user_id) as user_id\n",
    "                ,MAX(state_changed_on + time '5:30') as confirmed_on\n",
    "                ,MAX(channel) as channel\n",
    "                ,MAX(modified_by_id) as modified_by\n",
    "                FROM order_status_logs osl \n",
    "                LEFT JOIN orders o on o.id = osl.order_id\n",
    "                LEFT JOIN users u on u.id = o.user_id\n",
    "                WHERE to_state = 3 and state_changed_on > '2022-12-31 18:30:00'\n",
    "                GROUP BY od\n",
    "                ) AS ord) \n",
    "                AS ordr\n",
    "                WHERE order_number = 1\n",
    "                AND COALESCE(registered_at, '1970-01-01') >= CURRENT_DATE - INTERVAL '12 MONTH'\n",
    "                --AND EXTRACT(MONTH FROM confirmed_on) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "                AND confirmed_on >= '2024-10-31 18:30:00'\n",
    "                --AND EXTRACT(YEAR FROM confirmed_on) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "                ) as first_order\n",
    "                on first_order.od = order_Table.order_id\n",
    "                LEFT JOIN promotions promo on promo.id = order_Table.promotion_id\n",
    "                order by order_Table.confirmed_on\n",
    "  \n",
    "            ''')\n",
    "                \n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description] # Get column names from cursor description\n",
    "                df1 = pd.DataFrame(records, columns=columns) # Convert records to DataFrame\n",
    "                logging.info(f\"{len(records)} records fetched and saved to df\")\n",
    "                df = df1[['order_id', 'created_by_id', 'status', 'city_id', 'delivery_remarks',\n",
    "                         'payment_method', 'new_flag', 'order_value', 'shipping_charge',\n",
    "                         'detailed_status', 'out_for_delivery', 'confirmed_on', 'promotion_id',\n",
    "                         'shipped', 'fulfillment_center', 'slot_description', 'expected_delivery',\n",
    "                         'modified_by', 'reason', 'remarks', 'cancelled_date',\n",
    "                         'delivered_date', 'channel2', 'invoiced_amt', 'shipped_by',\n",
    "                         'exp_delivery_start', 'exp_delivery_end', 'delivery_flag', 'number','user_name' ,'pincode','wallet_amount'\n",
    "                         ,'order_action','actual_mapped_dc','coupon_code']]\n",
    "                logging.info(\"columns re-arranged in df\")\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            logging.info(f\"Error connecting to PostgreSQL : {error}\")\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                logging.info(\"PostgreSQL connection is closed\")\n",
    "        \n",
    "        logging.info(\"started updating Reorder sheet\")\n",
    "        gsheet_name = 'Reorder' #This google sheet will be updated\n",
    "        tab_name = 'C42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1WBLi5ShCGQ1US-x3OxPT2mXmz8sCn5UxiqtXJ16poBU\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f\"{gsheet_name} sheet Updated\")\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "        \n",
    "        gsheet_name = 'coupon_performance' #This google sheet will be updated\n",
    "        tab_name = 'c42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1E6r9p8Zn5jB-37kQu1Uu_OolOZocrrgOm2yQOtGJtT4\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f\"{gsheet_name} sheet Updated\")\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "    \n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        logging.info(f'Error connecting to PostgreSQL:{error}')\n",
    "    finally:# Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            logging.info(f'PostgreSQL connection is closed - job finished\\n')\n",
    "\n",
    "logging.info('Schedule the task to run every hour')\n",
    "#schedule.every().hours.at(\":50\").do(four_month_data)\n",
    "schedule.every(2).hours.at(\":30\").do(four_month_data)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bj_j0dOnDvEZ"
   },
   "outputs": [],
   "source": [
    "#Version : 2\n",
    "#Updates: added promotion details and updation in new sheet (coupon_performance) started\n",
    "#Updated_at : 19th feb 25\n",
    "#This Script Fetches last four Month Data - Order date is hard coded need to be update every month\n",
    "#else it will keep update more than 4 months order data into Reorder sheet\n",
    "\n",
    "# Orders are arranged in ascending order of confirmed on so that older data stays at the top\n",
    "# and newer data gets appended below and doesnot disturb CC Agens Disposition/Remarks\n",
    "\n",
    "import schedule as schedule\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"log_four_month_data.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def four_month_data():\n",
    "    try:\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import paramiko\n",
    "        import re\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                        host='127.0.0.1',\n",
    "                        port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                        database='efrprod',\n",
    "                        user='emamireaduser',\n",
    "                        password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "\n",
    "                # Perform database operations here\n",
    "                logging.info(\"Executing DB query to fetch orders data\")\n",
    "                cursor.execute(\n",
    "                '''\n",
    "                SELECT order_Table.*\n",
    "                ,CASE WHEN\n",
    "                \tod IS NULL THEN 'Not First Order'\n",
    "                \tELSE '1st Order' END AS new_flag\n",
    "                ,CASE\n",
    "                 \tWHEN timeout_at IS NOT NULL THEN 'timeout'\n",
    "                \tWHEN rejected_at IS NOT NULL THEN 'rejected'\n",
    "                \tWHEN accepted_at IS NOT NULL THEN 'accepted'\n",
    "                \tELSE 'pending' end as order_action\n",
    "                ,promo.coupon_code\n",
    "                FROM\n",
    "                (SELECT\n",
    "                 osl.order_id\n",
    "                ,o.user_id as created_by_id\n",
    "                ,CASE\n",
    "                \tWHEN o.state =0 THEN 'cart'\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\n",
    "                \tWHEN o.state =14  THEN 'Return_completed'\n",
    "                \tELSE 'In-Progress'\n",
    "                END AS status\n",
    "                ,o.city_id\n",
    "                ,o.delivery_remarks\n",
    "                ,o.payment_method\n",
    "                ,o.auto_completed\n",
    "                ,o.order_total_paise*1.0/100 AS order_value\n",
    "                ,o.shipping_total_paise*1.0/100 AS Shipping_charge\n",
    "                ,o.doctor_names\n",
    "                --,o.delivery_slot_id, o.store_id, o.shipping_address_id, o.billing_address_id\n",
    "                ,osl.confirmed_on\n",
    "                ,CASE\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\n",
    "                \tWHEN osl.channel = 1 THEN 'Mobile'\n",
    "                \tELSE 'Website'\n",
    "                END as channel_name\n",
    "                ,CASE\n",
    "                \tWHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                \tWHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                \tWHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                \tWHEN osl.channel = 0 THEN 'Call Center'\n",
    "                \tWHEN osl.channel = 1 THEN 'Saathi App'\n",
    "                \tELSE 'Website'\n",
    "                END as channel2\n",
    "                ,CASE\n",
    "                \tWHEN o.state =0 THEN 'cart'\n",
    "                \tWHEN o.state =1 THEN 'pre_checkout'\n",
    "                \tWHEN o.state =2 THEN 'Checkout'\n",
    "                \tWHEN o.state =3 THEN 'order_received'\n",
    "                \tWHEN o.state =4 THEN 'shipped'\n",
    "                \tWHEN o.state =5 THEN 'out_for_delivery'\n",
    "                \tWHEN o.state =6 THEN 'Delivered'\n",
    "                \tWHEN o.state =7 THEN 'Cancelled'\n",
    "                \tWHEN o.state =14 THEN 'Return_completed'\n",
    "                \tWHEN o.state =17 THEN 'rescheduled'\n",
    "                \t\tELSE 'In-Progress' END AS detailed_status\n",
    "                ,customer_id\n",
    "                ,users.name AS modified_by\n",
    "                ,w.code AS fulfillment_center\n",
    "                ,Wa.code AS Actual_Mapped_Dc\n",
    "                ,DS.slot_description\n",
    "                ,DS.slot_date AS Expected_Delivery\n",
    "                ,DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) AS exp_delivery_start\n",
    "                ,DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) AS exp_delivery_end\n",
    "                ,co.state_changed_on + time '5:30' as cancelled_date\n",
    "                ,co.reason\n",
    "                ,co.remarks\n",
    "                ,CASE\n",
    "                \tWHEN so.modified_by_id = 94098 THEN 'Ecogreen API'\n",
    "                \tWHEN so.modified_by_id = 25 THEN 'Vinculum API'\n",
    "                \tWHEN so.modified_by_id = 44306 THEN 'Delite'\n",
    "                \tWHEN so.modified_by_id = 162007 THEN 'Kumar Rohit'\n",
    "                \tWHEN so.modified_by_id = 175710 THEN 'Arun Kumar'\n",
    "                \tELSE 'Others'END AS shipped_by\n",
    "                ,so.state_changed_on + time '5:30'AS shipped\n",
    "                ,ofd.state_changed_on + time '5:30'AS out_for_delivery\n",
    "                ,del.state_changed_on + time '5:30'AS delivered_date\n",
    "                ,iv.amount_paise/100*1.0 AS invoiced_amt\n",
    "                ,iv.invoiced_at\n",
    "                ,iv.wallet_amount\n",
    "                ,ph.number\n",
    "                ,us.name AS user_name\n",
    "                ,us.created_at AS registration_date\n",
    "                ,us.registration_source\n",
    "                ,areas.pincode\n",
    "                ,op.promotion_id\n",
    "                ,op.promotion_total_paise/100*1.0 as amount_discounted\n",
    "                ,op.cash_back_total_paise/100*1.0 as cashback\n",
    "                --,promo.coupon_code\n",
    "                ,ROW_NUMBER() OVER(PARTITION BY o.user_id ORDER BY osl.confirmed_on) AS nth_order\n",
    "                --,CASE WHEN\n",
    "                --\tROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY osl.confirmed_on ASC) = 1\n",
    "                --\tTHEN '1st Order' ELSE 'Not First Order'\n",
    "                --END AS new_flag_month\n",
    "                ,CASE\n",
    "                \t WHEN del.state_changed_on + time '5:30' IS NULL THEN 'Undelivered'\n",
    "                \t WHEN del.state_changed_on + time '5:30'\n",
    "                \t < DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) THEN 'Early'\n",
    "                \t WHEN del.state_changed_on + time '5:30'\n",
    "                \t > DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME)\n",
    "                \t THEN 'Delay'\n",
    "                \t ELSE 'Between Slot'\n",
    "                END AS delivery_flag\n",
    "                ,oah_t.created_at + time '5:30' as timeout_at\n",
    "                ,oah_a.created_at + time '5:30' as accepted_at\n",
    "                ,oah_r.created_at + time '5:30' as rejected_at\n",
    "\n",
    "                FROM\n",
    "                \t(SELECT\n",
    "                \torder_id\n",
    "                \t,MAX(modified_by_id) modified_by_id\n",
    "                \t,MAX(channel) channel\n",
    "                \t,MAX(state_changed_on + time '5:30') AS confirmed_on\n",
    "                \tFROM order_status_logs\n",
    "                \tWHERE state_changed_on >'2024-10-31 18:30' AND to_state = 3\n",
    "                \tGROUP BY order_id) AS osl\n",
    "                LEFT JOIN orders o ON o.id = osl.order_id\n",
    "                LEFT JOIN users ON users.id = osl.modified_by_id\n",
    "                LEFT JOIN warehouses w ON w.id = o.fulfillment_center_id\n",
    "                LEFT JOIN warehouses wa ON wa.id = o.store_id\n",
    "                LEFT JOIN delivery_slots DS ON o.delivery_slot_id = DS.id\n",
    "                LEFT JOIN order_status_logs co ON co.order_id = osl.order_id AND co.to_state = 7 -- Calcelled Orders\n",
    "                LEFT JOIN order_status_logs so ON so.order_id = osl.order_id AND so.to_state = 4 -- Shipped Orders\n",
    "                LEFT JOIN order_status_logs ofd ON ofd.order_id = osl.order_id AND ofd.to_state = 5 -- out for delivery\n",
    "                LEFT JOIN order_status_logs del ON del.order_id = osl.order_id AND del.to_state = 6 -- out for delivery\n",
    "                LEFT JOIN invoices iv ON iv.order_id = osl.order_id\n",
    "                LEFT JOIN phones ph ON ph.user_id = o.user_id AND ph.deleted_at IS NULL\n",
    "                LEFT JOIN users us ON us.id = o.user_id\n",
    "                LEFT JOIN addresses ON addresses.id = o.shipping_address_id --to Get the area id\n",
    "                LEFT JOIN areas ON areas.id = addresses.area_id\n",
    "                LEFT JOIN order_assignment_histories oah_t on oah_t.order_id = osl.order_id AND oah_t.action = 'time_out'\n",
    "                LEFT JOIN order_assignment_histories oah_a on oah_a.order_id = osl.order_id AND oah_a.action = 'accept'\n",
    "                LEFT JOIN order_assignment_histories oah_r on oah_r.order_id = osl.order_id AND oah_r.action = 'reject'\n",
    "                LEFT JOIN order_promotions op on osl.order_id = op.order_id\n",
    "                ORDER BY osl.confirmed_on DESC) as order_Table\n",
    "                LEFT JOIN\n",
    "                (SELECT od FROM\n",
    "                (SELECT ord.*,\n",
    "                ROW_NUMBER() OVER (PARTITION BY ord.user_id ORDER BY ord.confirmed_on) AS order_number\n",
    "                FROM\n",
    "                (\n",
    "                SELECT\n",
    "                order_id as od\n",
    "                ,MAX(u.created_at) as registered_at\n",
    "                ,MAX(o.user_id) as user_id\n",
    "                ,MAX(state_changed_on + time '5:30') as confirmed_on\n",
    "                ,MAX(channel) as channel\n",
    "                ,MAX(modified_by_id) as modified_by\n",
    "                FROM order_status_logs osl\n",
    "                LEFT JOIN orders o on o.id = osl.order_id\n",
    "                LEFT JOIN users u on u.id = o.user_id\n",
    "                WHERE to_state = 3 and state_changed_on > '2022-12-31 18:30:00'\n",
    "                GROUP BY od\n",
    "                ) AS ord)\n",
    "                AS ordr\n",
    "                WHERE order_number = 1\n",
    "                AND COALESCE(registered_at, '1970-01-01') >= CURRENT_DATE - INTERVAL '12 MONTH'\n",
    "                --AND EXTRACT(MONTH FROM confirmed_on) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "                AND confirmed_on >= '2024-10-31 18:30:00'\n",
    "                --AND EXTRACT(YEAR FROM confirmed_on) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "                ) as first_order\n",
    "                on first_order.od = order_Table.order_id\n",
    "                LEFT JOIN promotions promo on promo.id = order_Table.promotion_id\n",
    "                order by order_Table.confirmed_on\n",
    "\n",
    "            ''')\n",
    "\n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description] # Get column names from cursor description\n",
    "                df1 = pd.DataFrame(records, columns=columns) # Convert records to DataFrame\n",
    "                logging.info(f\"{len(records)} records fetched and saved to df\")\n",
    "                df = df1[['order_id', 'created_by_id', 'status', 'city_id', 'delivery_remarks',\n",
    "                         'payment_method', 'new_flag', 'order_value', 'shipping_charge',\n",
    "                         'detailed_status', 'out_for_delivery', 'confirmed_on', 'promotion_id',\n",
    "                         'shipped', 'fulfillment_center', 'slot_description', 'expected_delivery',\n",
    "                         'modified_by', 'reason', 'remarks', 'cancelled_date',\n",
    "                         'delivered_date', 'channel2', 'invoiced_amt', 'shipped_by',\n",
    "                         'exp_delivery_start', 'exp_delivery_end', 'delivery_flag', 'number','user_name' ,'pincode','wallet_amount'\n",
    "                         ,'order_action','actual_mapped_dc','coupon_code']]\n",
    "                logging.info(\"columns re-arranged in df\")\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            logging.info(f\"Error connecting to PostgreSQL : {error}\")\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                logging.info(\"PostgreSQL connection is closed\")\n",
    "\n",
    "        logging.info(\"started updating Reorder sheet\")\n",
    "        gsheet_name = 'Reorder' #This google sheet will be updated\n",
    "        tab_name = 'C42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1WBLi5ShCGQ1US-x3OxPT2mXmz8sCn5UxiqtXJ16poBU\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f\"{gsheet_name} sheet Updated\")\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "\n",
    "        gsheet_name = 'coupon_performance' #This google sheet will be updated\n",
    "        tab_name = 'c42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1E6r9p8Zn5jB-37kQu1Uu_OolOZocrrgOm2yQOtGJtT4\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f\"{gsheet_name} sheet Updated\")\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        logging.info(f'Error connecting to PostgreSQL:')\n",
    "    finally:# Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            logging.info(f'PostgreSQL connection is closed - job finished\\n')\n",
    "\n",
    "logging.info('Schedule the task to run every hour')\n",
    "schedule.every().hours.at(\":52\").do(four_month_data)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZW6g-fDhCoNX"
   },
   "outputs": [],
   "source": [
    "#Version : 1\n",
    "#Updates: Working fine till 19th feb'25, updated to add promotions details\n",
    "#Updated_at : 19th feb 25\n",
    "#This Script Fetches last four Month Data - Order date is hard coded need to be update every month\n",
    "#else it will keep update more than 4 months order data into Reorder sheet\n",
    "\n",
    "# Orders are arranged in ascending order of confirmed on so that older data stays at the top\n",
    "# and newer data gets appended below and doesnot disturb CC Agens Disposition/Remarks\n",
    "\n",
    "import schedule as schedule\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"log_four_month_data.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def four_month_data():\n",
    "    try:\n",
    "        import csv\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import psycopg2\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import paramiko\n",
    "        import re\n",
    "        from sshtunnel import SSHTunnelForwarder\n",
    "        import gspread\n",
    "        from gspread_dataframe import set_with_dataframe\n",
    "        try:\n",
    "            # Create an SSH tunnel to the EC2 instance\n",
    "            with SSHTunnelForwarder(\n",
    "                ('65.1.183.184', 22),\n",
    "                ssh_username='ubuntu',\n",
    "                ssh_pkey=\"/home/rohit/emami-prod.pem\",\n",
    "                remote_bind_address=('emami-fr-prod-db.crknf6guwalh.ap-south-1.rds.amazonaws.com', 5432),\n",
    "                local_bind_address=('localhost', 5432)\n",
    "            ) as tunnel:\n",
    "                # Establish a connection to the RDS PostgreSQL database\n",
    "                connection = psycopg2.connect(\n",
    "                        host='127.0.0.1',\n",
    "                        port=tunnel.local_bind_port,  # This is the local port bound to the SSH tunnel\n",
    "                        database='efrprod',\n",
    "                        user='emamireaduser',\n",
    "                        password='emamireadaccess'\n",
    "                )\n",
    "                cursor = connection.cursor()\n",
    "\n",
    "                # Perform database operations here\n",
    "                logging.info(\"Executing DB query to fetch orders data\")\n",
    "                cursor.execute(\n",
    "                '''\n",
    "            SELECT order_Table.*\n",
    "            ,CASE WHEN\n",
    "                od IS NULL THEN 'Not First Order'\n",
    "                ELSE '1st Order' END AS new_flag\n",
    "            ,CASE\n",
    "                WHEN timeout_at IS NOT NULL THEN 'timeout'\n",
    "                WHEN rejected_at IS NOT NULL THEN 'rejected'\n",
    "                WHEN accepted_at IS NOT NULL THEN 'accepted'\n",
    "                ELSE 'pending' end as order_action\n",
    "            FROM\n",
    "            (SELECT\n",
    "             osl.order_id\n",
    "            ,o.user_id as created_by_id\n",
    "            ,CASE\n",
    "                WHEN o.state =0 THEN 'cart'\n",
    "                WHEN o.state =1 THEN 'pre_checkout'\n",
    "                WHEN o.state =2 THEN 'Checkout'\n",
    "                WHEN o.state =6 THEN 'Delivered'\n",
    "                WHEN o.state =7 THEN 'Cancelled'\n",
    "                WHEN o.state =14  THEN 'Return_completed'\n",
    "                ELSE 'In-Progress'\n",
    "            END AS status\n",
    "            ,o.city_id\n",
    "            ,o.delivery_remarks\n",
    "            ,o.payment_method\n",
    "            ,o.auto_completed\n",
    "            ,o.order_total_paise*1.0/100 AS order_value\n",
    "            ,o.shipping_total_paise*1.0/100 AS Shipping_charge\n",
    "            ,o.doctor_names\n",
    "            --,o.delivery_slot_id, o.store_id, o.shipping_address_id, o.billing_address_id\n",
    "            ,osl.confirmed_on\n",
    "            ,CASE\n",
    "                WHEN osl.channel = 0 THEN 'Call Center'\n",
    "                WHEN osl.channel = 1 THEN 'Mobile'\n",
    "                ELSE 'Website'\n",
    "            END as channel_name\n",
    "            ,CASE\n",
    "                WHEN o.customer_id IS NULL AND osl.channel = 1 THEN 'Mobile'\n",
    "                WHEN osl.channel = 0 AND COALESCE(o.delivery_remarks, '') LIKE '%FRSAATH%' THEN 'Saathi'\n",
    "                WHEN osl.channel = 0 AND osl.modified_by_id in(610295,383599,383941,436264) then 'Ecom_CC'\n",
    "                WHEN osl.channel = 0 THEN 'Call Center'\n",
    "                WHEN osl.channel = 1 THEN 'Saathi App'\n",
    "                ELSE 'Website'\n",
    "            END as channel2\n",
    "            ,CASE\n",
    "                WHEN o.state =0 THEN 'cart'\n",
    "                WHEN o.state =1 THEN 'pre_checkout'\n",
    "                WHEN o.state =2 THEN 'Checkout'\n",
    "                WHEN o.state =3 THEN 'order_received'\n",
    "                WHEN o.state =4 THEN 'shipped'\n",
    "                WHEN o.state =5 THEN 'out_for_delivery'\n",
    "                WHEN o.state =6 THEN 'Delivered'\n",
    "                WHEN o.state =7 THEN 'Cancelled'\n",
    "                WHEN o.state =14 THEN 'Return_completed'\n",
    "                WHEN o.state =17 THEN 'rescheduled'\n",
    "                    ELSE 'In-Progress' END AS detailed_status\n",
    "            ,customer_id\n",
    "            ,users.name AS modified_by\n",
    "            ,w.code AS fulfillment_center\n",
    "            ,Wa.code AS Actual_Mapped_Dc\n",
    "            ,DS.slot_description\n",
    "            ,DS.slot_date AS Expected_Delivery\n",
    "            ,DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) AS exp_delivery_start\n",
    "            ,DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME) AS exp_delivery_end\n",
    "            ,co.state_changed_on + time '5:30' as cancelled_date\n",
    "            ,co.reason\n",
    "            ,co.remarks\n",
    "            ,CASE\n",
    "                WHEN so.modified_by_id = 94098 THEN 'Ecogreen API'\n",
    "                WHEN so.modified_by_id = 25 THEN 'Vinculum API'\n",
    "                WHEN so.modified_by_id = 44306 THEN 'Delite'\n",
    "                WHEN so.modified_by_id = 162007 THEN 'Kumar Rohit'\n",
    "                WHEN so.modified_by_id = 175710 THEN 'Arun Kumar'\n",
    "                ELSE 'Others'END AS shipped_by\n",
    "            ,so.state_changed_on + time '5:30'AS shipped\n",
    "            ,ofd.state_changed_on + time '5:30'AS out_for_delivery\n",
    "            ,del.state_changed_on + time '5:30'AS delivered_date\n",
    "            ,iv.amount_paise/100*1.0 AS invoiced_amt\n",
    "            ,iv.invoiced_at\n",
    "            ,iv.wallet_amount\n",
    "            ,ph.number\n",
    "            ,us.name AS user_name\n",
    "            ,us.created_at AS registration_date\n",
    "            ,us.registration_source\n",
    "            ,areas.pincode\n",
    "            ,ROW_NUMBER() OVER(PARTITION BY o.user_id ORDER BY osl.confirmed_on) AS nth_order\n",
    "            --,CASE WHEN\n",
    "            --\tROW_NUMBER() OVER (PARTITION BY o.user_id ORDER BY osl.confirmed_on ASC) = 1\n",
    "            --\tTHEN '1st Order' ELSE 'Not First Order'\n",
    "            --END AS new_flag_month\n",
    "            ,CASE\n",
    "                 WHEN del.state_changed_on + time '5:30' IS NULL THEN 'Undelivered'\n",
    "                 WHEN del.state_changed_on + time '5:30'\n",
    "                 < DS.slot_date + CAST(SPLIT_PART(DS.slot_description, '-', 1) || ':00' AS TIME) THEN 'Early'\n",
    "                 WHEN del.state_changed_on + time '5:30'\n",
    "                 > DS.slot_date + CAST(TRIM(SPLIT_PART(DS.slot_description, '-', 2)) || ':00' AS TIME)\n",
    "                 THEN 'Delay'\n",
    "                 ELSE 'Between Slot'\n",
    "            END AS delivery_flag\n",
    "            ,oah_t.created_at + time '5:30' as timeout_at\n",
    "            ,oah_a.created_at + time '5:30' as accepted_at\n",
    "            ,oah_r.created_at + time '5:30' as rejected_at\n",
    "\n",
    "            FROM\n",
    "                (SELECT\n",
    "                order_id\n",
    "                ,MAX(modified_by_id) modified_by_id\n",
    "                ,MAX(channel) channel\n",
    "                ,MAX(state_changed_on + time '5:30') AS confirmed_on\n",
    "                FROM order_status_logs\n",
    "                WHERE state_changed_on >'2024-10-31 18:30' AND to_state = 3\n",
    "                GROUP BY order_id) AS osl\n",
    "            LEFT JOIN orders o ON o.id = osl.order_id\n",
    "            LEFT JOIN users ON users.id = osl.modified_by_id\n",
    "            LEFT JOIN warehouses w ON w.id = o.fulfillment_center_id\n",
    "            LEFT JOIN warehouses wa ON wa.id = o.store_id\n",
    "            LEFT JOIN delivery_slots DS ON o.delivery_slot_id = DS.id\n",
    "            LEFT JOIN order_status_logs co ON co.order_id = osl.order_id AND co.to_state = 7 -- Calcelled Orders\n",
    "            LEFT JOIN order_status_logs so ON so.order_id = osl.order_id AND so.to_state = 4 -- Shipped Orders\n",
    "            LEFT JOIN order_status_logs ofd ON ofd.order_id = osl.order_id AND ofd.to_state = 5 -- out for delivery\n",
    "            LEFT JOIN order_status_logs del ON del.order_id = osl.order_id AND del.to_state = 6 -- out for delivery\n",
    "            LEFT JOIN invoices iv ON iv.order_id = osl.order_id\n",
    "            LEFT JOIN phones ph ON ph.user_id = o.user_id AND ph.deleted_at IS NULL\n",
    "            LEFT JOIN users us ON us.id = o.user_id\n",
    "            LEFT JOIN addresses ON addresses.id = o.shipping_address_id --to Get the area id\n",
    "            LEFT JOIN areas ON areas.id = addresses.area_id\n",
    "            LEFT JOIN order_assignment_histories oah_t on oah_t.order_id = osl.order_id AND oah_t.action = 'time_out'\n",
    "            LEFT JOIN order_assignment_histories oah_a on oah_a.order_id = osl.order_id AND oah_a.action = 'accept'\n",
    "            LEFT JOIN order_assignment_histories oah_r on oah_r.order_id = osl.order_id AND oah_r.action = 'reject'\n",
    "            ORDER BY osl.confirmed_on DESC) as order_Table\n",
    "            LEFT JOIN\n",
    "            (SELECT od FROM\n",
    "            (SELECT ord.*,\n",
    "            ROW_NUMBER() OVER (PARTITION BY ord.user_id ORDER BY ord.confirmed_on) AS order_number\n",
    "            FROM\n",
    "            (\n",
    "            SELECT\n",
    "            order_id as od\n",
    "            ,MAX(u.created_at) as registered_at\n",
    "            ,MAX(o.user_id) as user_id\n",
    "            ,MAX(state_changed_on + time '5:30') as confirmed_on\n",
    "            ,MAX(channel) as channel\n",
    "            ,MAX(modified_by_id) as modified_by\n",
    "            FROM order_status_logs osl\n",
    "            LEFT JOIN orders o on o.id = osl.order_id\n",
    "            LEFT JOIN users u on u.id = o.user_id\n",
    "            WHERE to_state = 3 and state_changed_on > '2022-12-31 18:30:00'\n",
    "            GROUP BY od\n",
    "            ) AS ord)\n",
    "            AS ordr\n",
    "            WHERE order_number = 1\n",
    "            AND COALESCE(registered_at, '1970-01-01') >= CURRENT_DATE - INTERVAL '12 MONTH'\n",
    "            --AND EXTRACT(MONTH FROM confirmed_on) = EXTRACT(MONTH FROM CURRENT_DATE)\n",
    "            AND confirmed_on >= '2024-10-31 18:30:00'\n",
    "            --AND EXTRACT(YEAR FROM confirmed_on) = EXTRACT(YEAR FROM CURRENT_DATE)\n",
    "            ) as first_order\n",
    "            on first_order.od = order_Table.order_id\n",
    "            order by order_Table.confirmed_on\n",
    "                ''')\n",
    "\n",
    "                records = cursor.fetchall()\n",
    "                columns = [desc[0] for desc in cursor.description] # Get column names from cursor description\n",
    "                df1 = pd.DataFrame(records, columns=columns) # Convert records to DataFrame\n",
    "                logging.info(f\"{len(records)} records fetched and saved to df\")\n",
    "                df = df1[['order_id', 'created_by_id', 'status', 'city_id', 'delivery_remarks',\n",
    "                         'payment_method', 'new_flag', 'order_value', 'shipping_charge',\n",
    "                         'detailed_status', 'out_for_delivery', 'confirmed_on', 'channel_name',\n",
    "                         'shipped', 'fulfillment_center', 'slot_description', 'expected_delivery',\n",
    "                         'modified_by', 'reason', 'remarks', 'cancelled_date',\n",
    "                         'delivered_date', 'channel2', 'invoiced_amt', 'shipped_by',\n",
    "                         'exp_delivery_start', 'exp_delivery_end', 'delivery_flag', 'number','user_name' ,'pincode','wallet_amount'\n",
    "                         ,'order_action','actual_mapped_dc']]\n",
    "                logging.info(\"columns re-arranged in df\")\n",
    "\n",
    "        except (Exception, psycopg2.Error) as error:\n",
    "            logging.info(f\"Error connecting to PostgreSQL : {error}\")\n",
    "        finally:\n",
    "            # Close the database connection\n",
    "            if connection:\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "                logging.info(\"PostgreSQL connection is closed\")\n",
    "\n",
    "        logging.info(\"started updating Reorder sheet\")\n",
    "        gsheet_name = 'Reorder' #This google sheet will be updated\n",
    "        tab_name = 'C42' # This particular tab is to be updated\n",
    "        def write_df_to_gsheet (gsheet_name,tab_name,df):\n",
    "            gc = gspread.service_account(filename=\"summary-automation-project-fd46b6ab2eba.json\")\n",
    "            sh = gc.open_by_key(\"1WBLi5ShCGQ1US-x3OxPT2mXmz8sCn5UxiqtXJ16poBU\") #Key Of the google sheet - Summary_Epharmacy\n",
    "            worksheet = sh.worksheet(tab_name)\n",
    "            set_with_dataframe(worksheet,df)\n",
    "            logging.info(f\"{gsheet_name} sheet Updated\")\n",
    "        write_df_to_gsheet(gsheet_name,tab_name,df)\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        logging.info(f'Error connecting to PostgreSQL:')\n",
    "    finally:# Close the database connection\n",
    "        if connection:\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            logging.info(f'PostgreSQL connection is closed - job finished\\n')\n",
    "\n",
    "logging.info('Schedule the task to run every hour')\n",
    "schedule.every().hours.at(\":02\").do(four_month_data)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPUwUKa0aOFNk1ktXNZS1Za",
   "collapsed_sections": [
    "RhqLMc6N9fGF",
    "5zmUN30fKdML",
    "ZJoANfB-9arK",
    "FhiKmaFPLBoj"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
